{"version":3,"file":"static/js/2505.d2a6ef0f.chunk.js","mappings":"uIAAc,MAAOA,EAGnBC,WAAAA,CAAYC,EAAuBC,GACjCC,KAAKF,cAAgBA,EACrBE,KAAKD,aAAeA,CACtB,CAEAE,QAAAA,GACE,MAAO,GAAPC,OAAUF,KAAKF,cAAa,KAAAI,OAAIF,KAAKD,aACvC,CAEAI,SAAAA,CAAUC,GACR,OACEJ,KAAKF,cAAgBM,EAAEN,eAAiBE,KAAKD,aAAeK,EAAEL,YAElE,CAEA,UAAOM,GACL,IAAIA,EACAC,EAAI,EAAC,QAAAC,EAAAC,UAAAC,OAFGC,EAAqB,IAAAC,MAAAJ,GAAAK,EAAA,EAAAA,EAAAL,EAAAK,IAArBF,EAAqBE,GAAAJ,UAAAI,GAGjC,MAAQP,EAAKC,GAAK,EAChBD,EAAMK,EAAKJ,GAEb,KAAOA,EAAII,EAAKD,OAAQH,GAAK,EACvBD,EAAIF,UAAUO,EAAKJ,IAAM,IAC3BD,EAAMK,EAAKJ,IAGf,OAAOD,CACT,EAEI,SAAUQ,EAAUC,GAA4C,IAA7BC,EAAMP,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAG,EAChD,GAD4DA,UAAAC,OAAA,QAAAO,IAAAR,UAAA,IAAAA,UAAA,GAE1D,MAAM,IAAIS,MAAM,mDAGlB,OAAO,IAAIrB,EACW,cAApBkB,EAAMC,EAAS,GACO,WAApBD,EAAMC,EAAS,GACK,SAApBD,EAAMC,EAAS,GACK,MAApBD,EAAMC,EAAS,GACK,IAApBD,EAAMC,EAAS,GACfD,EAAMC,EAAS,GAChBD,EAAMC,EAAS,IAAM,EAAKD,EAAMC,GAErC,CC3Cc,MAAOG,EAGnBrB,WAAAA,CACSsB,EACAC,EACAC,EACAC,GAHA,KAAAH,KAAAA,EACA,KAAAC,KAAAA,EACA,KAAAC,IAAAA,EACA,KAAAC,aAAAA,CACN,CAEHC,cAAAA,GACE,MAAO,GAAPrB,OAAUF,KAAKmB,KAAI,MAAAjB,OAAKF,KAAKoB,KAAI,UAAAlB,OAC/BF,KAAKqB,IACP,kBAAAnB,OAAiBF,KAAKwB,cAAa,IACrC,CAEAvB,QAAAA,GACE,OAAOD,KAAKuB,gBACd,CAEApB,SAAAA,CAAUC,GACR,OACEJ,KAAKmB,KAAKhB,UAAUC,EAAEe,OACtBnB,KAAKoB,KAAKjB,UAAUC,EAAEgB,OACtBpB,KAAKqB,IAAMjB,EAAEiB,GAEjB,CAEAG,WAAAA,GACE,YAA0BR,IAAtBhB,KAAKsB,aACAtB,KAAKsB,aAEPtB,KAAKoB,KAAKtB,cAAgB,MAAYE,KAAKmB,KAAKrB,aACzD,E,wBChCI,SAAU2B,EAAQC,GACtB,OAAO,IAAIC,SAAQC,GAAWC,WAAWD,EAASF,IACpD,CAuBM,SAAUI,EAAiBC,GAC/B,GAAKA,GAIDA,EAAOC,QAAS,CAElB,GAA4B,qBAAjBC,aAA8B,CACvC,MAAMC,EAAI,IAAIjB,MAAM,WAGpB,MADAiB,EAAEC,KAAO,cACHD,C,CAEN,MAAM,IAAID,aAAa,UAAW,a,CAGxC,CAmCM,SAAUG,EAAeC,EAAiBC,GAC9C,MAAMC,EAAwB,GAC9B,IAAIC,EAEJ,GAAsB,IAAlBH,EAAO5B,OACT,OAAO4B,EAGTA,EAAOI,MAAK,CAACC,EAAIC,KACf,MAAMC,EAAMF,EAAGvB,KAAKrB,cAAgB6C,EAAGxB,KAAKrB,cAC5C,OAAe,IAAR8C,EAAYF,EAAGvB,KAAKpB,aAAe4C,EAAGxB,KAAKpB,aAAe6C,CAAG,IAGtE,IAAK,MAAMC,KAASR,IACbC,GAAUO,EAAMzB,KAAKjB,UAAUmC,GAAU,UAC1BtB,IAAdwB,GACFD,EAAaO,KAAKD,GAClBL,EAAYK,IAvCWE,EAyCJP,GAzCmBQ,EAyCRH,GAvC3B1B,KAAKrB,cAAgBiD,EAAO3B,KAAKtB,cAAgB,MACxDkD,EAAO5B,KAAKtB,cAAgBiD,EAAO5B,KAAKrB,cAAgB,IAuC9C+C,EAAMzB,KAAKjB,UAAUqC,EAAUpB,MAAQ,IACzCoB,EAAUpB,KAAOyB,EAAMzB,OAGzBmB,EAAaO,KAAKD,GAClBL,EAAYK,KA/ChB,IAAyBE,EAAeC,EAqD5C,OAAOT,CACT,CAEM,SAAUU,EAAenC,EAAeC,GAO5C,MAAO,CAAEmC,UAjHL,SAAuBC,GAC3B,GACEA,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBAErB,MAAM,IAAIvC,MAAM,oBAElB,OAAOkC,EAAKM,UACd,CAmGoBC,CAChBC,IAAAA,YACEhD,MAAMiD,UAAUC,MAAMC,KAAKhD,EAAOC,EAAQA,EAAS,IACnD,IAIN,CAEM,SAAUgD,EACdC,EACAC,GAEA,OAAOD,EACHA,EAAc7D,UAAU8D,GAAiB,EACvCA,EACAD,EACFC,CACN,CAEM,SAAUC,EACdC,GAC8C,IAA9CC,EAAA5D,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAwC6D,GAAKA,EAEzCC,EAAY,EACZC,EAAgB,EACpB,MAAMC,EAAc,GACdC,EAAyC,CAAC,EAChD,IAAK,IAAInE,EAAI,EAAGA,EAAI6D,EAAW1D,OAAQH,GAAK,EAC1C,IAAK6D,EAAW7D,GAAI,CAClB,GAAIiE,EAAgBjE,EAAG,CACrB,IAAIoE,EAAUP,EAAWlE,SAAS,OAAQsE,EAAejE,GACzDoE,EAAUN,EAAaM,GACvBF,EAAYF,GAAaI,EACzBD,EAAYC,GAAWJ,C,CAEzBC,EAAgBjE,EAAI,EACpBgE,GAAa,C,CAGjB,MAAO,CAAEG,cAAaD,cACxB,CCxJc,MAAgBG,EAQ5B9E,WAAAA,CAAA+E,GAMC,IANW,WACVC,EAAU,aACVT,EAAgBU,IAAcA,IAI/BF,EACC5E,KAAK6E,WAAaA,EAClB7E,KAAKoE,aAAeA,CACtB,ECMY,MAAOW,UAAYJ,EAG/B,eAAMzB,CAAU8B,EAAeC,G,QAE7B,OAAsC,QAA/BC,EAAwB,QAAxBC,SADiBnF,KAAKoF,MAAMH,IAClBI,QAAQL,UAAM,IAAAG,OAAA,EAAAA,EAAEG,aAAK,IAAAJ,OAAA,EAAAA,EAAEhC,YAAa,CACvD,CAGA,YAAMqC,CAAON,GACX,MAAMnE,QAAed,KAAK6E,WAAWW,SAASP,GAG9C,GAlCc,WAkCVnE,EAAM2E,aAAa,GACrB,MAAM,IAAIxE,MAAM,kBAGlB,MAAMyE,EAAW5E,EAAM6E,YAAY,GAKnC,IACI3B,EADA4B,EAAO,EAKX,MAAMP,EAAU,IAAI1E,MAIjB+E,GACH,IAAK,IAAIpF,EAAI,EAAGA,EAAIoF,EAAUpF,IAAK,CAEjC,MAAMuF,EAAW/E,EAAM6E,YAAYC,GACnC,IAAIN,EAEJM,GAAQ,EACR,MAAME,EAAuC,CAAC,EAE9C,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAAG,CACpC,MAAM1E,EAAMP,EAAM2E,aAAaG,GAE/B,GADAA,GAAQ,EACII,QAAR3E,EACFuE,GAAQ,EACRN,EAAQrC,EAAenC,EAAO8E,EAAO,IACrCA,GAAQ,OACH,IAAIvE,EAAM2E,MACf,MAAM,IAAI/E,MAAM,oDACX,CACL,MAAMgF,EAAanF,EAAM6E,YAAYC,GACrCA,GAAQ,EACR,MAAMvD,EAAS,IAAI1B,MAAasF,GAChC,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,IAAK,CACnC,MAAMC,EAAItF,EAAUC,EAAO8E,GAC3BA,GAAQ,EACR,MAAMQ,EAAIvF,EAAUC,EAAO8E,GAC3BA,GAAQ,EACR5B,EAAgBD,EAAcC,EAAemC,GAC7C9D,EAAO6D,GAAK,IAAIhF,EAAMiF,EAAGC,EAAG/E,E,CAE9ByE,EAASzE,GAAOgB,C,GAIpB,MAAMgE,EAAcvF,EAAM6E,YAAYC,GACtCA,GAAQ,EAIR,MAAMU,EAAc,IAAI3F,MAAqB0F,GAC7C,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAaN,IAAK,CACpC,MAAMhF,EAASF,EAAUC,EAAO8E,GAChCA,GAAQ,EACR5B,EAAgBD,EAAcC,EAAejD,GAC7CuF,EAAYP,GAAKhF,C,CAGnBsE,EAAQ/E,GAAK,CAAEwF,WAAUQ,cAAahB,Q,CAGxC,MAAO,CACLiB,KAAK,EACLvC,gBACAwC,aAAc,MACdnB,UACAK,WAEJ,CAEA,cAAMe,CACJC,EACAC,EACAC,GACmB,IAAnB3B,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAElB,MAAM4F,EAAI,MACJS,OAAkB7F,IAAV2F,EAERG,SADkB9G,KAAKoF,MAAMH,IACVI,QAAQqB,GACjC,IAAKI,EACH,MAAO,GAET,MAAM,YAAER,EAAc,GAAE,MAAEhB,GAAUwB,EACpC,GAA2B,IAAvBR,EAAY7F,OACd,MAAO,GAET,MAAMyB,OAAYlB,IAAR4F,GAAqBN,EAAY7F,OAAS,GAAK2F,GA3H5CtB,EA2HwD8B,GA1H3D9B,GADciC,EA2HkDX,GA1HhDW,EAD9B,IAAiBjC,EAAWiC,EA4HxB,MAAM1C,OAAcrD,IAAV2F,EAAsB,EA/HpC,SAAmB7B,EAAWiC,GAC5B,OAAOjC,EAAKA,EAAIiC,CAClB,CA6HwCC,CAAUL,EAAOP,GAC/Ca,EACF,IAAItG,MADOkG,GACA3E,EAAImC,GAAK+B,EACVE,EAAY7F,OAAS,GAC7ByG,EAAYZ,EAAYA,EAAY7F,OAAS,GAAGX,cACtD,GAAIoC,GAAKoE,EAAY7F,OAAS,GAAK2F,EACjC,MAAM,IAAInF,MAAM,0CAElB,IAAIkG,EAAab,EAAYjC,EAAI+B,GAAGtG,cACpC,IAAK,IAAIQ,EAAI+D,EAAI+B,EAAGL,EAAI,EAAGzF,EAAI4B,EAAIkE,EAAG9F,IAAKyF,IACzCkB,EAAOlB,GAAK,CACVqB,MAAOd,EAAYhG,EAAI,GAAGR,cAAgBqH,EAC1CR,MAAOrG,EAAI8F,EACXQ,IAAKtG,EAAI8F,EAAIA,GAEfe,EAAab,EAAYhG,EAAI,GAAGR,cAElC,OAAOmH,EAAOI,KAAIC,IAAK,IAClBA,EACHF,MAAQE,EAAEF,QAAc,OAAL9B,QAAK,IAALA,OAAK,EAALA,EAAOpC,YAAa,GAAMgE,KAEjD,CAEA,oBAAMK,CACJvC,EACA3E,EACAmH,GACmB,IAAnBvC,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAEdH,EAAM,IACRA,EAAM,GAGR,MAAMoH,QAAkBzH,KAAKoF,MAAMH,GACnC,IAAKwC,EACH,MAAO,GAET,MAAMC,EAAKD,EAAUpC,QAAQL,GAC7B,IAAK0C,EACH,MAAO,GAIT,MAAMC,GAnKqBf,EAmKWY,EAjKjC,CACL,CAAC,EAAG,GACJ,CAAC,IAJaI,EAmKmBvH,IA/JpB,IAAK,IAHpBuG,GAAO,IAGyB,KAC9B,CAAC,GAAKgB,GAAO,IAAK,GAAKhB,GAAO,KAC9B,CAAC,IAAMgB,GAAO,IAAK,IAAMhB,GAAO,KAChC,CAAC,KAAOgB,GAAO,IAAK,KAAOhB,GAAO,KAClC,CAAC,MAAQgB,GAAO,IAAK,MAAQhB,GAAO,OARxC,IAAkBgB,EAAahB,EAoK3B,MAAMvE,EAAkB,GAGxB,IAAK,MAAOsE,EAAOC,KAAQe,EACzB,IAAK,IAAItG,EAAMsF,EAAOtF,GAAOuF,EAAKvF,IAChC,GAAIqG,EAAG5B,SAASzE,GAAM,CACpB,MAAMwG,EAAYH,EAAG5B,SAASzE,GAC9B,IAAK,MAAMyG,KAAYD,EACrBxF,EAAOS,KAAKgF,E,CAQpB,MAAMC,EAAQL,EAAGpB,YAAY7F,OAC7B,IAAI6B,EACJ,MAAM0F,EAASC,KAAK5H,IAAIA,GAAO,GAAI0H,EAAQ,GACrCG,EAASD,KAAK5H,IAAImH,GAAO,GAAIO,EAAQ,GAC3C,IAAK,IAAIzH,EAAI0H,EAAQ1H,GAAK4H,IAAU5H,EAAG,CACrC,MAAM6H,EAAKT,EAAGpB,YAAYhG,GACtB6H,KAAQ7F,GAAU6F,EAAGhI,UAAUmC,GAAU,KAC3CA,EAAS6F,E,CAIb,OAAO/F,EAAeC,EAAQC,EAChC,CAEA,WAAM8C,GAAyB,IAAnBH,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAO5B,OANKR,KAAKoI,SACRpI,KAAKoI,OAASpI,KAAKuF,OAAON,GAAMoD,OAAMnG,IAEpC,MADAlC,KAAKoI,YAASpH,EACRkB,CAAC,KAGJlC,KAAKoI,MACd,CAEA,eAAME,CAAU5B,GAAkC,IAAnBzB,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,E,MAE/C,SAA8B,QAArB2E,SADYnF,KAAKoF,MAAMH,IAChBI,QAAQqB,UAAM,IAAAvB,OAAA,EAAAA,EAAEW,SAClC,E,gGC3MF,SAASyC,EAAOC,EAAaC,GAC3B,OAAOR,KAAKS,MAAMF,EAAM,GAAKC,EAC/B,CAEc,MAAOE,UAAYhE,EAAjC9E,WAAAA,G,oBACU,KAAA+I,aAAe,EACf,KAAAC,MAAQ,EACR,KAAAC,SAAW,CA+MrB,CA3ME,eAAM5F,CAAU8B,EAAeC,G,QAE7B,OAAsC,QAA/BC,EAAwB,QAAxBC,SADiBnF,KAAKoF,MAAMH,IAClBI,QAAQL,UAAM,IAAAG,OAAA,EAAAA,EAAEG,aAAK,IAAAJ,OAAA,EAAAA,EAAEhC,YAAa,CACvD,CAEA,cAAMuD,GACJ,MAAO,EACT,CAEAsC,YAAAA,CAAajI,EAAeC,GAC1B,MAAMiI,EAAclI,EAAM6E,YAAY5E,GAChCkI,EACU,MAAdD,EAAwB,uBAAyB,iBAC7CE,EACJ,CAAE,EAAG,UAAW,EAAG,MAAO,EAAG,OAGf,GAAdF,GACF,IAAKE,EACH,MAAM,IAAIjI,MAAM,qCAADf,OAAsC8I,IAEvD,MAAMG,EAAgB,CACpBC,IAAKtI,EAAM6E,YAAY5E,EAAS,GAChC4F,MAAO7F,EAAM6E,YAAY5E,EAAS,GAClC6F,IAAK9F,EAAM6E,YAAY5E,EAAS,KAE5BsI,EAAYvI,EAAM6E,YAAY5E,EAAS,IACvCuI,EAAWD,EAAYE,OAAOC,aAAaH,GAAa,GACxDI,EAAY3I,EAAM6E,YAAY5E,EAAS,IACvC2I,EAAoB5I,EAAM6E,YAAY5E,EAAS,IAErD,MAAO,CACLoI,gBACAF,iBACAI,YACAC,WACAG,YACAP,SACAF,iBACG9E,EACDpD,EAAM6I,SAAS5I,EAAS,GAAIA,EAAS,GAAK2I,GAC1C1J,KAAKoE,cAGX,CAGA,YAAMmB,CAAON,GACX,MAAM2E,QAAe5J,KAAK6E,WAAWW,SAASP,GACxCnE,QAAc+I,EAAAA,EAAAA,OAAMD,GAE1B,IAAIE,EAEJ,GAtEe,WAsEXhJ,EAAM2E,aAAa,GACrBqE,EAAa,MACR,IAvEQ,WAuEJhJ,EAAM2E,aAAa,GAG5B,MAAM,IAAIxE,MAAM,kBAFhB6I,EAAa,C,CAMf9J,KAAK8I,SAAWhI,EAAM6E,YAAY,GAClC3F,KAAK6I,MAAQ/H,EAAM6E,YAAY,GAC/B3F,KAAK4I,eAAiB,GAAyB,GAAlB5I,KAAK6I,MAAQ,IAAW,GAAK,EAC1D,MAAMkB,EAAYjJ,EAAM6E,YAAY,IAC9BqE,EAAMD,GAAa,GAAK/J,KAAK+I,aAAajI,EAAO,SAAME,EACvD0E,EAAW5E,EAAM6E,YAAY,GAAKoE,GAKxC,IACI/F,EADA4B,EAAO,GAAKmE,EAAY,EAE5B,MAAM1E,EAAU,IAAI1E,MAGjB+E,GACH,IAAK,IAAIpF,EAAI,EAAGA,EAAIoF,EAAUpF,IAAK,CAEjC,MAAMuF,EAAW/E,EAAM6E,YAAYC,GACnCA,GAAQ,EACR,MAAME,EAAuC,CAAC,EAC9C,IAAIR,EACJ,IAAK,IAAIS,EAAI,EAAGA,EAAIF,EAAUE,IAAK,CACjC,MAAM1E,EAAMP,EAAM2E,aAAaG,GAE/B,GADAA,GAAQ,EACJvE,EAAMrB,KAAK4I,aACbtD,EAAQrC,EAAenC,EAAO8E,EAAO,IACrCA,GAAQ,OACH,CACL5B,EAAgBD,EAAcC,EAAenD,EAAUC,EAAO8E,IAC9DA,GAAQ,EACR,MAAMK,EAAanF,EAAM6E,YAAYC,GACrCA,GAAQ,EACR,MAAMvD,EAAS,IAAI1B,MAAasF,GAChC,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,GAAK,EAAG,CACtC,MAAMC,EAAItF,EAAUC,EAAO8E,GAC3BA,GAAQ,EACR,MAAMQ,EAAIvF,EAAUC,EAAO8E,GAC3BA,GAAQ,EACR5B,EAAgBD,EAAcC,EAAemC,GAC7C9D,EAAO6D,GAAK,IAAIhF,EAAMiF,EAAGC,EAAG/E,E,CAE9ByE,EAASzE,GAAOgB,C,EAIpBgD,EAAQ/E,GAAK,CAAEwF,WAAUR,Q,CAG3B,MAAO,CACLwE,aACA9F,gBACAqB,UACAK,WACAuE,KAAK,EACLzD,aAAc,SACXwD,EAEP,CAEA,oBAAMzC,CACJvC,EACA3E,EACAmH,GACmB,IAAnBvC,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAEdH,EAAM,IACRA,EAAM,GAGR,MAAMoH,QAAkBzH,KAAKoF,MAAMH,GAC7ByC,EAAc,OAATD,QAAS,IAATA,OAAS,EAATA,EAAWpC,QAAQL,GAC9B,IAAK0C,EACH,MAAO,GAET,MAAMC,EAAkB3H,KAAKkK,SAAS7J,EAAKmH,GAE3C,GAA+B,IAA3BG,EAAgBlH,OAClB,MAAO,GAGT,MAAM4B,EAAS,GAEf,IAAK,MAAOsE,EAAOC,KAAQe,EACzB,IAAK,IAAItG,EAAMsF,EAAOtF,GAAOuF,EAAKvF,IAChC,GAAIqG,EAAG5B,SAASzE,GAAM,CACpB,MAAMwG,EAAYH,EAAG5B,SAASzE,GAC9B,IAAK,MAAM8I,KAAKtC,EACdxF,EAAOS,KAAKqH,E,CAMpB,OAAO/H,EAAeC,EAAQ,IAAIzC,EAAc,EAAG,GACrD,CAMAsK,QAAAA,CAAStC,EAAahB,IACpBgB,GAAO,GACG,IACRA,EAAM,GAEJhB,EAAM,GAAK,KACbA,EAAM,GAAK,IAEbA,GAAO,EACP,IAAIwD,EAAI,EACJC,EAAI,EACJhG,EAAIrE,KAAK8I,SAAwB,EAAb9I,KAAK6I,MAC7B,MAAMyB,EAAO,GACb,KAAOF,GAAKpK,KAAK6I,MAAOxE,GAAK,EAAGgG,GAAY,EA7LjC,IA6LwC,EAAJD,GAAQA,GAAK,EAAG,CAC7D,MAAMhK,EAAIiK,EAAI9B,EAAOX,EAAKvD,GACpBnC,EAAImI,EAAI9B,EAAO3B,EAAKvC,GAC1B,GAAInC,EAAI9B,EAAIkK,EAAK7J,OAAST,KAAK4I,aAC7B,MAAM,IAAI3H,MAAM,SAADf,OACJ0H,EAAG,KAAA1H,OAAI0G,EAAG,oDAAA1G,OAAmDF,KAAK8I,SAAQ,YAAA5I,OAAWF,KAAK6I,MAAK,6DAG5GyB,EAAKxH,KAAK,CAAC1C,EAAG8B,G,CAEhB,OAAOoI,CACT,CAEA,WAAMlF,GAAyB,IAAnBH,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAO5B,OANKR,KAAKoI,SACRpI,KAAKoI,OAASpI,KAAKuF,OAAON,GAAMoD,OAAMnG,IAEpC,MADAlC,KAAKoI,YAASpH,EACRkB,CAAC,KAGJlC,KAAKoI,MACd,CAEA,eAAME,CAAU5B,GAAkC,IAAnBzB,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,E,MAE/C,SAA8B,QAArB2E,SADYnF,KAAKoF,MAAMH,IAChBI,QAAQqB,UAAM,IAAAvB,OAAA,EAAAA,EAAEW,SAClC,ECxOF,QAEe,EAFf,EAIoB,EAJpB,EAMc,EANd,EAQe,EARf,EAUgB,GAVhB,EAYiB,GAZjB,EAcc,GAdd,EAgBc,IAhBd,EAkBkB,IAlBlB,EAoBe,IApBf,EAsBY,KAtBZ,EAwBsB,KCrBhByE,EAAiB,mBAAmBC,MAAM,IAC1CC,EAAgB,mBAAmBD,MAAM,IAKjC,MAAOE,EAUnB7K,WAAAA,CAAYa,GATJ,KAAAiK,KAAO,CAAC,EAIR,KAAAC,SAAqB,GACrB,KAAAC,gBAAiB,EAKvB,MAAM,MAAE/J,EAAK,WAAEgK,GAAepK,GACxB,UAAEqK,EAAS,MAAEpE,GAAU7F,EAC7Bd,KAAK2K,KAAO,CAAC,EACb3K,KAAKc,MAAQA,EACbd,KAAKgL,IAAMF,EACX9K,KAAKiL,OAASF,EAAUpF,YAAYgB,EAAQ,GAC5C3G,KAAK2K,KAAKhE,MAAQoE,EAAUpF,YAAYgB,EAAQ,GAChD3G,KAAKkL,OAA6C,WAApCH,EAAUpF,YAAYgB,EAAQ,MAAqB,EACnE,CAEAwE,GAAAA,CAAIC,GAEF,OAAIpL,KAAKoL,IAEHpL,KAAK2K,KAAKS,KAIdpL,KAAK2K,KAAKS,GAASpL,KAAKoL,MAHfpL,KAAK2K,KAAKS,IAMdpL,KAAKqL,KAAKD,EAAME,cACzB,CAEA1E,GAAAA,GACE,OAAO5G,KAAKmL,IAAI,SAAWnL,KAAKmL,IAAI,gBACtC,CAEAI,MAAAA,GACE,OAAOvL,KAAKiL,MACd,CAIAI,IAAAA,CAAKD,GACH,OAAIA,KAASpL,KAAK2K,OAGlB3K,KAAK2K,KAAKS,GAASpL,KAAKwL,UAAUJ,IAFzBpL,KAAK2K,KAAKS,EAIrB,CAEAK,KAAAA,GACEzL,KAAK0L,gBAEL,IAAIC,EAAO,CAAC,OAEP3L,KAAK4L,qBACRD,EAAK7I,KACH,QACA,MACA,SACA,QACA,OACA,KACA,QACA,gBACA,mBAGA9C,KAAK6L,YACPF,EAAK7I,KAAK,wBAAyB,oBAErC6I,EAAOA,EAAKzL,OAAOF,KAAK4K,UAAY,IAEpC,IAAK,MAAM1E,KAAK4F,OAAOC,KAAK/L,KAAK2K,MAClB,MAATzE,EAAE,IAAoB,gBAANA,GAClByF,EAAK7I,KAAKoD,GAId,MAAM8F,EAAmC,CAAC,EAC1C,OAAOL,EAAKM,QAAO5B,IACjB,GACGA,KAAKrK,KAAK2K,WAAyB3J,IAAjBhB,KAAK2K,KAAKN,IACvB,OAANA,GACM,OAANA,EAEA,OAAO,EAGT,MAAM6B,EAAK7B,EAAEiB,cACPjH,EAAI2H,EAAKE,GAEf,OADAF,EAAKE,IAAM,GACH7H,CAAC,GAEb,CAEA8H,MAAAA,GAEA,CAEAC,QAAAA,GACE,OAAOpM,KAAKmL,IAAI,cAClB,CAEAkB,EAAAA,GACE,OAAOrM,KAAKgL,GACd,CAMAsB,EAAAA,GACE,MAAMA,GAA+B,MAAzBtM,KAAKmL,IAAI,gBAA2B,EAChD,OAAc,MAAPmB,OAAatL,EAAYsL,CAClC,CAEAlF,KAAAA,GACE,OAAOpH,KAAKmL,IAAI,KAClB,CAEAoB,IAAAA,G,MACE,OAAqB,QAAdpH,EAAAnF,KAAKwM,iBAAS,IAAArH,OAAA,EAAAA,EAAEsH,KAAK,IAC9B,CAEAD,OAAAA,GACE,GAAIxM,KAAK4L,oBACP,OAGF,MAAM,MAAEjF,EAAK,UAAEoE,GAAc/K,KAAKc,MAC5B4L,EACJ/F,EACA,GACA3G,KAAKmL,IAAI,gBACiB,EAA1BnL,KAAKmL,IAAI,eACTnL,KAAKmL,IAAI,cACLwB,EAAO3M,KAAKmL,IAAI,cACtB,OAAOJ,EAAUpB,SAAS+C,EAAGA,EAAIC,EACnC,CAEAC,MAAAA,GACE,OAAO5M,KAAK6M,yBAA2B,EAAI,CAC7C,CAEAC,iCAAAA,GACE,IAAI9M,KAAK+M,iBAGT,OAAO/M,KAAKgN,6BAA+B,EAAI,CACjD,CAEAC,IAAAA,GACE,OAAOjN,KAAKmL,IAAI,aAClB,CAEA+B,UAAAA,GACE,MAAMC,EAAKnN,KAAKmL,IAAI,iBACd,UAAEJ,EAAS,MAAEpE,GAAU3G,KAAKc,MAClC,OAAOiK,EAAU9K,SAAS,QAAS0G,EAAQ,GAAIA,EAAQ,GAAKwG,EAAK,EACnE,CAMA3B,SAAAA,CAAU4B,GAIR,GAAIpN,KAAK6K,eACP,OAGF,MAAM,UAAEE,EAAS,MAAEpE,GAAU3G,KAAKc,MAClC,IAAI4L,EACF1M,KAAKqN,YACL1G,EACE,GACA3G,KAAKmL,IAAI,gBACiB,EAA1BnL,KAAKmL,IAAI,eACTnL,KAAKmL,IAAI,cACTnL,KAAKmL,IAAI,cAEb,MAAMmC,EAAWtN,KAAKc,MAAM8F,IAC5B,IAAI2G,EACJ,KAAOb,EAAIY,GAAYC,IAAUH,GAAS,CACxC,MAAMI,EAAMjE,OAAOC,aAAauB,EAAU2B,GAAI3B,EAAU2B,EAAI,IAC5Da,EAAQC,EAAIlC,cACZ,MAAMmC,EAAOlE,OAAOC,aAAauB,EAAU2B,EAAI,IAG/C,IAAIgB,EACJ,OAHAhB,GAAK,EAGGe,GACN,IAAK,IACHC,EAAQnE,OAAOC,aAAauB,EAAU2B,IACtCA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ3C,EAAUpF,YAAY+G,GAC9BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ3C,EAAUtF,aAAaiH,GAC/BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ3C,EAAU4C,SAASjB,GAC3BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ3C,EAAU6C,UAAUlB,GAC5BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ3C,EAAU8C,YAAYnB,GAC9BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ3C,EAAU+C,aAAapB,GAC/BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ3C,EAAUgD,YAAYrB,GAC9BA,GAAK,EACL,MAEF,IAAK,IACL,IAAK,IAEH,IADAgB,EAAQ,GACDhB,GAAKY,GAAU,CACpB,MAAMU,EAAKjD,EAAU2B,KACrB,GAAW,IAAPsB,EACF,MAEAN,GAASnE,OAAOC,aAAawE,E,CAGjC,MAEF,IAAK,IAAK,CACRN,EAAQ,GACR,MAAMM,EAAKjD,EAAU2B,KACfuB,EAAQ1E,OAAOC,aAAawE,GAC5BE,EAAQnD,EAAUpF,YAAY+G,GAEpC,GADAA,GAAK,EACS,MAAVuB,EACF,GAAY,OAART,EACF,IAAK,IAAItH,EAAI,EAAGA,EAAIgI,EAAOhI,IAAK,CAC9B,MAAMiI,EAAQpD,EAAUpF,YAAY+G,GAGpCgB,IAFYS,GAAS,GACV1D,EAAsB,GAAR0D,GAEzBzB,GAAK,C,MAGP,IAAK,IAAIxG,EAAI,EAAGA,EAAIgI,EAAOhI,IACzBwH,GAAS3C,EAAUpF,YAAY+G,GAC3BxG,EAAI,EAAIgI,IACVR,GAAS,KAEXhB,GAAK,EAIX,GAAc,MAAVuB,EACF,GAAY,OAART,EACF,IAAK,IAAItH,EAAI,EAAGA,EAAIgI,EAAOhI,IAAK,CAC9B,MAAMiI,EAAQpD,EAAUtF,aAAaiH,GAGrCgB,IAFYS,GAAS,GACV1D,EAAsB,GAAR0D,GAEzBzB,GAAK,C,MAGP,IAAK,IAAIxG,EAAI,EAAGA,EAAIgI,EAAOhI,IACzBwH,GAAS3C,EAAUtF,aAAaiH,GAC5BxG,EAAI,EAAIgI,IACVR,GAAS,KAEXhB,GAAK,EAIX,GAAc,MAAVuB,EACF,IAAK,IAAI/H,EAAI,EAAGA,EAAIgI,EAAOhI,IACzBwH,GAAS3C,EAAU8C,YAAYnB,GAC3BxG,EAAI,EAAIgI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAI/H,EAAI,EAAGA,EAAIgI,EAAOhI,IACzBwH,GAAS3C,EAAU+C,aAAapB,GAC5BxG,EAAI,EAAIgI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAI/H,EAAI,EAAGA,EAAIgI,EAAOhI,IACzBwH,GAAS3C,EAAU4C,SAASjB,GACxBxG,EAAI,EAAIgI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAI/H,EAAI,EAAGA,EAAIgI,EAAOhI,IACzBwH,GAAS3C,EAAU6C,UAAUlB,GACzBxG,EAAI,EAAIgI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAI/H,EAAI,EAAGA,EAAIgI,EAAOhI,IACzBwH,GAAS3C,EAAUgD,YAAYrB,GAC3BxG,EAAI,EAAIgI,IACVR,GAAS,KAEXhB,GAAK,EAGT,K,CAEF,QACE0B,QAAQC,KAAK,yBAADnO,OAA0BuN,EAAI,8BAC1CC,OAAQ1M,EACR0L,EAAIY,EAOR,GAHAtN,KAAKqN,WAAaX,EAElB1M,KAAK4K,SAAS9H,KAAK0K,GACfD,IAAUH,EACZ,OAAOM,EAGT1N,KAAK2K,KAAK4C,GAASG,C,CAErB1N,KAAK6K,gBAAiB,CAExB,CAEAa,aAAAA,GACE1L,KAAKwL,UAAU,GACjB,CAEA8C,WAAAA,CAAYC,GACV,OAEEA,EACGC,MAAM,UAENnH,KAAIoH,GAAM,CAACA,EAAGD,MAAM,MAAM,GAAGE,cAAerL,OAAOsL,SAASF,EAAI,MAEvE,CAKA5C,QAAAA,GACE,SAAU7L,KAAKkL,MAAQ0D,EACzB,CAGAC,gBAAAA,GACE,SAAU7O,KAAKkL,MAAQ0D,EACzB,CAGAhD,iBAAAA,GACE,SAAU5L,KAAKkL,MAAQ0D,EACzB,CAGA7B,cAAAA,GACE,SAAU/M,KAAKkL,MAAQ0D,EACzB,CAGA/B,qBAAAA,GACE,SAAU7M,KAAKkL,MAAQ0D,EACzB,CAGA5B,yBAAAA,GACE,SAAUhN,KAAKkL,MAAQ0D,EACzB,CAGAE,OAAAA,GACE,SAAU9O,KAAKkL,MAAQ0D,EACzB,CAGAG,OAAAA,GACE,SAAU/O,KAAKkL,MAAQ0D,EACzB,CAGAI,WAAAA,GACE,SAAUhP,KAAKkL,MAAQ0D,EACzB,CAGAK,UAAAA,GACE,SAAUjP,KAAKkL,MAAQ0D,EACzB,CAGAM,WAAAA,GACE,SAAUlP,KAAKkL,MAAQ0D,EACzB,CAGAO,eAAAA,GACE,SAAUnP,KAAKkL,MAAQ0D,EACzB,CAEAL,KAAAA,GACE,GAAIvO,KAAK4L,oBACP,OAGF,MAAM,UAAEb,EAAS,MAAEpE,GAAU3G,KAAKc,MAC5BsO,EAAcpP,KAAKmL,IAAI,eAC7B,IAAIuB,EAAI/F,EAAQ,GAAK3G,KAAKmL,IAAI,gBAC9B,MAAMkE,EAASrP,KAAKmL,IAAI,cACxB,IAAIoD,EAAQ,GACRe,EAAO,EAIPnB,EAAQpD,EAAUpF,YAAY+G,GAC9B6C,EAAMpB,GAAS,EACfM,EAAKhE,EAAsB,GAAR0D,GACvB,GAAW,MAAPM,GAAcc,IAAQF,EAWxB,OARA3C,GAAK,EACLyB,EAAQpD,EAAUpF,YAAY+G,GAC9B6C,EAAMpB,GAAS,EACfM,EAAKhE,EAAsB,GAAR0D,GACR,MAAPM,GACFL,QAAQC,KAAK,wBAEfrO,KAAK2K,KAAK6E,cAAgBD,EACnBvP,KAAKmL,IAAI,MAEhB,IAAK,IAAIhB,EAAI,EAAGA,EAAIiF,IAAejF,EACjCgE,EAAQpD,EAAUpF,YAAY+G,GAC9B6C,EAAMpB,GAAS,EACfM,EAAKhE,EAAsB,GAAR0D,GACnBI,GAASgB,EAAMd,EAIJ,MAAPA,GAAqB,MAAPA,GAAqB,MAAPA,IAC9Ba,GAAQC,GAGV7C,GAAK,EAIP,OADA1M,KAAK2K,KAAK6E,cAAgBF,EACnBf,CAEX,CAEAkB,MAAAA,GAAU,CAEVD,aAAAA,GACE,OAAIxP,KAAK2K,KAAK6E,eAGZxP,KAAKmL,IAAI,SAFFnL,KAAK2K,KAAK6E,aAKrB,CAEAE,WAAAA,GACE,OAA8B,MAAvB1P,KAAKmL,IAAI,WAClB,CAEAwE,YAAAA,GACE,OAAgC,IAAzB3P,KAAKmL,IAAI,aAClB,CAKAyE,UAAAA,GACE,OAAQ5P,KAAKmL,IAAI,cAAgB,GAAM,CACzC,CAEA0E,YAAAA,GACE,OAAO7P,KAAK8P,KACd,CAEAA,GAAAA,GACE,MAAM,UAAE/E,EAAS,MAAEpE,GAAU3G,KAAKc,MAC5B4L,EACJ/F,EAAQ,GAAK3G,KAAKmL,IAAI,gBAA4C,EAA1BnL,KAAKmL,IAAI,eAC7C4E,EAAW/P,KAAKmL,IAAI,cACpB6E,EAAMhQ,KAAKmL,IAAI,cACrB,IAAI8E,EAAM,GACN3P,EAAI,EACR,IAAK,IAAIyF,EAAI,EAAGA,EAAIgK,IAAYhK,EAAG,CACjC,MAAMmK,EAAKnF,EAAU2B,EAAI3G,GACzBkK,GAAO1F,GAAqB,IAAL2F,IAAc,GACrC5P,IACIA,EAAI0P,IACNC,GAAO1F,EAAoB,GAAL2F,GACtB5P,I,CAGJ,OAAO2P,CACT,CAGAE,kBAAAA,GACE,IACGnQ,KAAK4L,sBACL5L,KAAK+M,kBACN/M,KAAKiL,SAAWjL,KAAKoQ,cACrB,CACA,MAAMC,EAAKrQ,KAAK6M,wBAA0B,IAAM,IAC1CyD,EAAKtQ,KAAKgN,4BAA8B,IAAM,IACpD,IAAIuD,EAAK,IACLC,EAAK,IACLxQ,KAAK8O,WACPyB,EAAK,IACLC,EAAK,KACIxQ,KAAK+O,YACdwB,EAAK,IACLC,EAAK,KAGP,MAAMC,EAAM,GAaZ,OAZczQ,KAAK0Q,kBACP,GACVD,EAAI,GAAKJ,EACTI,EAAI,GAAKF,EACTE,EAAI,GAAKH,EACTG,EAAI,GAAKD,IAETC,EAAI,GAAKJ,EACTI,EAAI,GAAKF,EACTE,EAAI,GAAKH,EACTG,EAAI,GAAKD,GAEJC,EAAIhE,KAAK,G,CAElB,MAAO,EACT,CAEAkE,UAAAA,GACE,OAAO3Q,KAAKc,MAAMiK,UAAUpF,YAAY3F,KAAKc,MAAM6F,MAAQ,GAC7D,CAEAiK,QAAAA,GACE,OAAO5Q,KAAKc,MAAMiK,UAAUpF,YAAY3F,KAAKc,MAAM6F,MAAQ,GAC7D,CAEAkK,UAAAA,GACE,OAAO7Q,KAAKc,MAAMiK,UAAUpF,YAAY3F,KAAKc,MAAM6F,MAAQ,GAC7D,CAEAyJ,WAAAA,GACE,OAAOpQ,KAAKc,MAAMiK,UAAUpF,YAAY3F,KAAKc,MAAM6F,MAAQ,GAC7D,CAEAmK,SAAAA,GACE,OAAO9Q,KAAKc,MAAMiK,UAAUpF,YAAY3F,KAAKc,MAAM6F,MAAQ,GAC7D,CAEA+J,eAAAA,GACE,OAAO1Q,KAAKc,MAAMiK,UAAUpF,YAAY3F,KAAKc,MAAM6F,MAAQ,GAC7D,CAEAoK,MAAAA,GACE,MAAMpG,EAA+B,CAAC,EACtC,IAAK,MAAMzE,KAAK4F,OAAOC,KAAK/L,MACN,MAAhBkG,EAAE8K,OAAO,IAAoB,UAAN9K,IAI3ByE,EAAKzE,GAAKlG,KAAKkG,IAGjB,OAAOyE,CACT,EC1mBI,SAAUsG,EAAgBC,GAC9B,MAAMC,EAAQD,EAAK1G,MAAM,SACnBG,EAAkE,GACxE,IAAK,MAAMyG,KAAQD,EAAO,CACxB,MAAO3D,KAAQ6D,GAAUD,EAAK5G,MAAM,MAChCgD,GACF7C,EAAK7H,KAAK,CACR0K,IAAKA,EAAI3J,MAAM,GACf8G,KAAM0G,EAAOhK,KAAIiK,IACf,MAAOC,EAAU7D,GAAS4D,EAAE9G,MAAM,IAAK,GACvC,MAAO,CAAEgD,IAAK+D,EAAU7D,QAAO,K,CAKvC,OAAO/C,CACT,CCDO,MAAM6G,EAAY,SAiBzB,MAAMC,EACGC,IAAAA,GACL,MAAM,IAAIzQ,MAAM,eAClB,CACO0Q,IAAAA,GACL,MAAM,IAAI1Q,MAAM,eAClB,CAEOuE,QAAAA,GACL,MAAM,IAAIvE,MAAM,eAClB,CAEO2Q,KAAAA,GACL,MAAM,IAAI3Q,MAAM,eAClB,EAEY,MAAO4Q,EAyBnBhS,WAAAA,CAAA+E,GA0BC,IA1BW,cACVkN,EAAa,QACbC,EAAO,OACPC,EAAM,QACNC,EAAO,cACPC,EAAa,OACbC,EAAM,QACNC,EAAO,cACPC,EAAa,OACbC,EAAM,OACNC,EAAM,gBACNC,EAAkB,IAAG,cACrBC,EAAgB3N,IAAKA,IActBF,EAGC,GA9CK,KAAA2N,QAAS,EAGR,KAAAG,aAAe,IAAIC,IAAJ,CAA8C,CACnEC,MAAO,IAAIC,IAAJ,CAAa,CAClBC,QAAS,KAEXC,KAAMC,MAAOtS,EAAYqB,KACvB,MAAM,MAAEc,EAAK,KAAEoC,GAASvE,GAClB,KAAEiK,EAAI,WAAEsI,EAAU,WAAEC,SAAqBlT,KAAKmT,WAAW,CAC7DtQ,QACAoC,KAAM,IAAKA,EAAMlD,YAEnB,OAAO/B,KAAKoT,gBAAgBzI,EAAMsI,EAAYC,EAAYrQ,EAAM,IA+BlE7C,KAAKoE,aAAeqO,EAEhBX,EACF9R,KAAKqT,IAAMvB,OACN,GAAIC,EACT/R,KAAKqT,IAAM,IAAIC,EAAAA,GAAUvB,QACpB,GAAIC,EACThS,KAAKqT,IAAM,IAAIE,EAAAA,GAAWvB,OACrB,KAAIO,EAIT,MAAM,IAAItR,MAAM,4BAHhBjB,KAAKuS,QAAS,EACdvS,KAAKqT,IAAM,IAAI5B,C,CAIjB,GAAIY,EACFrS,KAAKwT,MAAQ,IAAI7K,EAAI,CAAE9D,WAAYwN,SAC9B,GAAID,EACTpS,KAAKwT,MAAQ,IAAI7K,EAAI,CAAE9D,WAAY,IAAIyO,EAAAA,GAAUlB,UAC5C,GAAIE,EACTtS,KAAKwT,MAAQ,IAAI7K,EAAI,CAAE9D,WAAY,IAAI0O,EAAAA,GAAWjB,UAC7C,GAAIJ,EACTlS,KAAKwT,MAAQ,IAAIzO,EAAI,CAAEF,WAAYqN,SAC9B,GAAID,EACTjS,KAAKwT,MAAQ,IAAIzO,EAAI,CAAEF,WAAY,IAAIyO,EAAAA,GAAUrB,UAC5C,GAAIE,EACTnS,KAAKwT,MAAQ,IAAIzO,EAAI,CAAEF,WAAY,IAAI0O,EAAAA,GAAWpB,UAC7C,GAAIJ,EACT/R,KAAKwT,MAAQ,IAAIzO,EAAI,CAAEF,WAAY,IAAIyO,EAAAA,GAAU,GAADpT,OAAI6R,EAAO,gBACtD,GAAIC,EACThS,KAAKwT,MAAQ,IAAIzO,EAAI,CAAEF,WAAY,IAAI0O,EAAAA,GAAW,GAADrT,OAAI8R,EAAM,eACtD,KAAIO,EAGT,MAAM,IAAItR,MAAM,gCAFhBjB,KAAKuS,QAAS,C,CAIhBvS,KAAKwS,gBAAkBA,CACzB,CAEA,kBAAMiB,CAAaC,GACjB,MAAMzO,EP/DJ,WAAmD,IAAhC0O,EAAAnT,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAA8B,CAAC,EACtD,MAAO,YAAamT,EAAO,CAAE5R,OAAQ4R,GAAsBA,CAC7D,CO6DiBC,CAASF,GACtB,IAAK1T,KAAKwT,MACR,OAEF,MAAM/L,QAAkBzH,KAAKwT,MAAMpO,MAAMH,GACnC4O,EAAMpM,EAAUzD,cAClByD,EAAUzD,cAAclE,cAAgB,WACxCkB,EACJ,IAAI4I,EACJ,GAAIiK,EAAK,CACP,MAAMxP,EAAIwP,EApIC,MAqILC,QAAY9T,KAAKqT,IAAI3B,KAAKqC,EAAAA,OAAOC,MAAM3P,GAAI,EAAGA,EAAG,EAAGY,GAC1D,IAAK6O,EAAIG,UACP,MAAM,IAAIhT,MAAM,wBAElB2I,EAASkK,EAAIlK,OAAOD,SAAS,EAAG1B,KAAK5H,IAAIyT,EAAIG,UAAWJ,G,MAExDjK,QAAgB5J,KAAKqT,IAAI7N,SAASP,GAGpC,MAAMiP,QAAcrK,EAAAA,EAAAA,OAAMD,GAE1B,GAAIsK,EAAMvO,YAAY,KAAO6L,EAC3B,MAAM,IAAIvQ,MAAM,kBAElB,MAAMkT,EAAUD,EAAMvO,YAAY,GAElC3F,KAAKoU,OAASF,EAAMjU,SAAS,OAAQ,EAAG,EAAIkU,GAC5C,MAAM,WAAEE,EAAU,WAAEC,SAAqBtU,KAAKuU,aAC5CJ,EAAU,EACV,MACAlP,GAKF,OAHAjF,KAAKqU,WAAaA,EAClBrU,KAAKsU,WAAaA,EAEXrD,EAAgBjR,KAAKoU,OAC9B,CAEAI,SAAAA,CAAUvP,GAOR,OANKjF,KAAKyU,UACRzU,KAAKyU,QAAUzU,KAAKyT,aAAaxO,GAAMoD,OAAMnG,IAE3C,MADAlC,KAAKyU,aAAUzT,EACTkB,CAAC,KAGJlC,KAAKyU,OACd,CAEA,mBAAMC,GAAiC,IAAnBzP,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAEpC,aADMR,KAAKwU,UAAUvP,GACdjF,KAAKoU,MACd,CAIA,kBAAMG,CACJ5N,EACAgO,EACA1P,GAKA,GAAI0B,EAAQgO,EACV,OAAO3U,KAAKuU,aAAa5N,EAAqB,EAAdgO,EAAiB1P,GAEnD,MAAM2P,EAAOD,EA7LA,OA8LP,UAAEV,EAAS,OAAErK,SAAiB5J,KAAKqT,IAAI3B,KAC3CqC,EAAAA,OAAOC,MAAMY,GACb,EACAD,EACA,EACA1P,GAEF,IAAKgP,EACH,MAAM,IAAIhT,MAAM,qCAElB,MAAMiT,QAAcrK,EAAAA,EAAAA,OAClBD,EAAOD,SAAS,EAAG1B,KAAK5H,IAAI4T,EAAWU,KAEnCE,EAAOX,EAAMvO,YAAYgB,GAC/B,IAAI+F,EAAI/F,EAAQ,EAChB,MAAM0N,EAAwC,CAAC,EACzCC,EAAoD,GAC1D,IAAK,IAAIhU,EAAI,EAAGA,EAAIuU,EAAMvU,GAAK,EAAG,CAChC,MAAMwU,EAAQZ,EAAMvO,YAAY+G,GAC1BhI,EAAU1E,KAAKoE,aACnB8P,EAAMjU,SAAS,OAAQyM,EAAI,EAAGA,EAAI,EAAIoI,EAAQ,IAE1CC,EAAOb,EAAMvO,YAAY+G,EAAIoI,EAAQ,GAM3C,GAJAT,EAAW3P,GAAWpE,EACtBgU,EAAWxR,KAAK,CAAE4B,UAASjE,OAAQsU,IAEnCrI,EAAIA,EAAI,EAAIoI,EACRpI,EAAIwH,EAAMzT,OAIZ,OAHA2N,QAAQC,KAAK,wCAADnO,OAC8ByU,EAAW,YAE9C3U,KAAKuU,aAAa5N,EAAqB,EAAdgO,EAAiB1P,E,CAGrD,MAAO,CAAEoP,aAAYC,aACvB,CAEA,wBAAMU,CACJC,EACA5U,EACAmH,EACAvC,GAEA,OAxOJ+N,eAA4BkC,GAC1B,IAAIC,EAAW,GACf,UAAW,MAAMC,KAAKF,EACpBC,EAAMA,EAAIjV,OAAOkV,GAEnB,OAAOD,CACT,CAkOWE,CAAUrV,KAAKsV,sBAAsBL,EAAK5U,EAAKmH,EAAKvC,GAC7D,CAEA,2BAAOqQ,CACLL,EACA5U,EACAmH,EACAvC,G,YAEMjF,KAAKwU,UAAUvP,GACrB,MAAMsQ,EAAuB,QAAfpQ,EAAAnF,KAAKqU,kBAAU,IAAAlP,OAAA,EAAAA,EAAG8P,GAChC,QAAcjU,IAAVuU,GAAwBvV,KAAKwT,MAE1B,CACL,MAAMnR,QAAerC,KAAKwT,MAAMjM,eAAegO,EAAOlV,EAAM,EAAGmH,EAAKvC,SAC7DjF,KAAKwV,oBAAoBnT,EAAQkT,EAAOlV,EAAKmH,EAAKvC,E,WAHnD,EAKV,CAEOuQ,mBAAAA,CACLnT,EACAkT,EACAlV,EACAmH,GAAW,QAAAiO,EAAA,SACXxQ,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAgB,CAAC,EAAC,yBAElB,MAAM,YAAEkV,GAAgBzQ,EAClB0Q,EAAQ,GACd,IAAIC,GAAO,EAEX,IAAK,MAAM/S,KAASR,EAAQ,CAC1B,MAAMwT,QAAgBJ,EAAK/C,aAAavH,IACtCtI,EAAM5C,WACN,CAAE4C,QAAOoC,QACTA,EAAKlD,QAGD+T,EAAO,GACb,IAAK,MAAMC,KAAWF,EACpB,GAAIE,EAAQxK,WAAagK,EAAO,CAC9B,GAAIQ,EAAQ5K,IAAI,UAAY3D,EAAK,CAE/BoO,GAAO,EACP,K,CACSG,EAAQ5K,IAAI,QAAU9K,GAE/ByV,EAAKhT,KAAKiT,E,CAMhB,GAFAJ,EAAM7S,KAAKgT,SACLA,EACFF,EACF,K,CAIJ9T,EAAiBmD,EAAKlD,QAClB2T,UACID,EAAKO,WAAWT,EAAOI,EAAO1Q,GAExC,CArCoB,EAqCnB,OAAA/C,GAAA,OAAAP,QAAAsU,OAAA/T,EAAA,EAED,gBAAM8T,CAAWT,EAAeI,EAAuB1Q,GACrD,MAAM,cAAEiR,EAAa,cAAEC,EAAgB,KAAWlR,EAC5CmR,EAA2C,CAAC,EAC5CC,EAAqC,CAAC,EAC5CV,EAAMtO,KAAIwM,IACR,MAAMyC,EAAuC,CAAC,EAC9C,IAAK,MAAMC,KAAW1C,EAAK,CACzB,MAAM5G,EAAOsJ,EAAQtJ,OACfZ,EAAKkK,EAAQlK,KACdiK,EAAUrJ,KACbqJ,EAAUrJ,GAAQ,GAEpBqJ,EAAUrJ,KACVoJ,EAAQhK,GAAM,C,CAEhB,IAAK,MAAOnG,EAAGE,KAAM0F,OAAO0K,QAAQF,GACxB,IAANlQ,IACFgQ,EAAalQ,IAAK,E,IAKxB,MAAMuQ,EAAmC,GACzCd,EAAMtO,KAAIwM,IACR,IAAK,MAAMvC,KAAKuC,EAAK,CACnB,MAAM5G,EAAOqE,EAAErE,OACTtG,EAAQ2K,EAAEnG,IAAI,SACduL,EAAQpF,EAAER,YACV6F,EAAQrF,EAAElB,cAEdpQ,KAAKwT,OACL4C,EAAanJ,KACZiJ,GACES,IAAUpB,GAAStN,KAAK2O,IAAIjQ,EAAQ+P,GAASP,IAEhDM,EAAa3T,KACX9C,KAAKwT,MAAMjM,eAAeoP,EAAOD,EAAOA,EAAQ,EAAGzR,G,KAQ3D,MAAMoC,EAAM,IAAIwP,IACV/C,QAAYnS,QAAQmV,IAAIL,GAC9B,IAAK,MAAMM,KAAKjD,EAAIkD,OACb3P,EAAI4P,IAAIF,EAAE9W,aACboH,EAAI6P,IAAIH,EAAE9W,WAAY8W,GAwB1B,aApB+BpV,QAAQmV,IACrC,IAAIzP,EAAI8P,UAAU9P,KAAI2L,UACpB,MAAM,KAAErI,EAAI,WAAEsI,EAAU,WAAEC,EAAU,MAAErQ,SAAgB7C,KAAKmT,WAAW,CACpEtQ,MAAOsH,EACPlF,SAEImS,EAAW,GACjB,IAAK,MAAMrB,WAAiB/V,KAAKoT,gBAC/BzI,EACAsI,EACAC,EACArQ,GAEIuT,EAAaL,EAAQ5K,IAAI,WAAakL,EAAQN,EAAQ1J,OACxD+K,EAAStU,KAAKiT,GAGlB,OAAOqB,CAAQ,MAGKJ,MAC1B,CAEA,iBAAMK,CAAYC,EAAkB1C,GAAiC,IAAnB3P,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAClE,MAAM,UAAEyT,EAAS,OAAErK,SAAiB5J,KAAKqT,IAAI3B,KAC3CqC,EAAAA,OAAOC,MAAMY,GACb,EACAA,EACA0C,EACArS,GAGF,OAAO2E,EAAOD,SAAS,EAAG1B,KAAK5H,IAAI4T,EAAWW,GAChD,CAEA,gBAAMzB,CAAUoE,GAAkD,IAAjD,MAAE1U,EAAK,KAAEoC,GAAwCsS,EAChE,MAAM3N,QAAe5J,KAAKqX,YACxBxU,EAAM1B,KAAKrB,cACX+C,EAAMrB,cACNyD,IAIA2E,OAAQe,EAAI,WACZsI,EAAU,WACVC,SACQsE,EAAAA,EAAAA,IAAgB5N,EAAQ/G,GAClC,MAAO,CAAE8H,OAAMsI,aAAYC,aAAYrQ,QACzC,CAEA,qBAAMuQ,CACJ1L,EACAuL,EACAC,EACArQ,GAEA,IAAI4U,EAAa,EACjB,MAAMC,EAAO,GACb,IAAIC,EAAM,EACNC,GAAQC,KAAKC,MAEjB,KAAOL,EAAa,EAAI/P,EAAGjH,QAAQ,CACjC,MACM6M,EAAWmK,EAAa,EADZ/P,EAAG/B,YAAY8R,GACa,EAG9C,GAAIvE,EAAY,CACd,KAAOuE,EAAa5U,EAAM1B,KAAKpB,cAAgBmT,EAAWyE,OAC1DA,G,CAIF,GAAIrK,EAAW5F,EAAGjH,OAAQ,CACxB,MAAMsV,EAAU,IAAIgC,EAAW,CAC7BjX,MAAO,CACLiK,UAAWrD,EACXf,MAAO8Q,EACP7Q,IAAK0G,GAsBPxC,WACEmI,EAAWxS,OAAS,EACE,IAAlBwS,EAAW0E,IACVF,EAAavE,EAAWyE,IACzB9U,EAAM1B,KAAKpB,aACX,EAEAiY,IAAAA,OAAatQ,EAAG7D,MAAM4T,EAAYnK,MAG1CoK,EAAK5U,KAAKiT,GACN/V,KAAKwS,kBAAoBqF,KAAKC,MAAQF,EAAO5X,KAAKwS,wBAC9C/Q,EAAQ,GACdmW,GAAQC,KAAKC,M,CAIjBL,EAAanK,EAAW,C,CAE1B,OAAOoK,CACT,CAEA,eAAMpP,CAAU2P,G,QACd,MAAMvR,EAAuB,QAAfvB,EAAAnF,KAAKqU,kBAAU,IAAAlP,OAAA,EAAAA,EAAG8S,GAChC,YAAiBjX,IAAV0F,IAAwC,QAAVxB,EAAAlF,KAAKwT,aAAK,IAAAtO,OAAA,EAAAA,EAAEoD,UAAU5B,GAC7D,CAEA,eAAMxD,CAAU+U,G,MACd,MAAMvR,EAAuB,QAAfvB,EAAAnF,KAAKqU,kBAAU,IAAAlP,OAAA,EAAAA,EAAG8S,GAChC,YAAiBjX,IAAV0F,GAAwB1G,KAAKwT,MAAYxT,KAAKwT,MAAMtQ,UAAUwD,GAAzB,CAC9C,CAEA,cAAMD,CAASwR,EAAiBtR,EAAgBC,G,MAC9C,IAAK5G,KAAKwT,MACR,MAAO,SAEHxT,KAAKwT,MAAMpO,QACjB,MAAMsB,EAAuB,QAAfvB,EAAAnF,KAAKqU,kBAAU,IAAAlP,OAAA,EAAAA,EAAG8S,GAChC,YAAiBjX,IAAV0F,EAAsB,GAAK1G,KAAKwT,MAAM/M,SAASC,EAAOC,EAAOC,EACtE,CAEA,oBAAMW,CACJ0Q,EACAtR,EACAC,EACA3B,G,MAEA,IAAKjF,KAAKwT,MACR,MAAO,SAEHxT,KAAKwT,MAAMpO,QACjB,MAAMsB,EAAuB,QAAfvB,EAAAnF,KAAKqU,kBAAU,IAAAlP,OAAA,EAAAA,EAAG8S,GAChC,YAAiBjX,IAAV0F,EACH,GACA1G,KAAKwT,MAAMjM,eAAeb,EAAOC,EAAOC,EAAK3B,EACnD,EC7fF+N,eAAe9S,EAAOgY,EAAoBjT,GACxC,MAAM6O,QAAYnS,QAAQmV,IACxBoB,EAAI7Q,KAAI2L,UACN,MAAM,IAAEmF,EAAG,QAAEC,GAAYvV,EACzB,GAAIsV,EAAIE,WAAW,SACjB,OAAOtE,EAAAA,OAAOuE,KAAKH,EAAI3N,MAAM,KAAK,GAAI,UACjC,CAIL,MAAM,QAAE+N,KAAYC,GAASJ,EACvBtE,QAAY2E,MAAMN,EAAK,IACxBlT,EACHmT,QAAS,IAAS,OAAJnT,QAAI,IAAJA,OAAI,EAAJA,EAAMmT,WAAYI,KAElC,IAAK1E,EAAI4E,GACP,MAAM,IAAIzX,MAAM,QAADf,OACL4T,EAAI6E,OAAM,cAAAzY,OAAaiY,EAAG,MAAAjY,aAAW4T,EAAI5C,SAGrD,OAAO6C,EAAAA,OAAOuE,WAAWxE,EAAI8E,c,MAKnC,OAAO7E,EAAAA,OAAO7T,aAAayB,QAAQmV,IAAIhD,EAAIzM,KAAIwR,IAAOhP,EAAAA,EAAAA,OAAMgP,MAC9D,CAEc,MAAOC,UAAmBjH,EAKtChS,WAAAA,CAAYa,GACVqY,MAAM,CAAExG,QAAQ,IAChBvS,KAAKgZ,QAAUtY,EAAKsY,QACpBhZ,KAAKiZ,QAAUvY,EAAKuY,OACtB,CAEA,2BAAO3D,CACLL,EACA5U,EACAmH,EACAvC,G,MAEA,MAAMiU,EAAO,GAAHhZ,OAAMF,KAAKgZ,QAAO,KAAA9Y,OAAIF,KAAKiZ,SAC/Bd,EAAM,GAAHjY,OAAMgZ,EAAI,mBAAAhZ,OAAkB+U,EAAG,WAAA/U,OAAUG,EAAG,SAAAH,OAAQsH,EAAG,eAC1D+N,EAAuB,QAAfpQ,EAAAnF,KAAKqU,kBAAU,IAAAlP,OAAA,EAAAA,EAAG8P,GAChC,QAAcjU,IAAVuU,OACI,OACD,CACL,MAAM4D,QAAeV,MAAMN,EAAK,IAAKlT,IACrC,IAAKkU,EAAOT,GACV,MAAM,IAAIzX,MAAM,QAADf,OACLiZ,EAAOR,OAAM,cAAAzY,OAAaiY,EAAG,MAAAjY,aAAWiZ,EAAOjI,SAG3D,MAAMvG,QAAawO,EAAOC,OACpBlF,QAAchU,EAAOyK,EAAK4H,OAAO8G,KAAKxV,MAAM,GAAIoB,SAE/CjF,KAAKwV,oBACV,CAEE,CACE5L,OAAQsK,EACR5S,kBAAcN,EACdK,IAAK,EACLlB,UAASA,IACA,EAEToB,eAAcA,IACL,GAAPrB,OAAU+U,EAAG,KAAA/U,OAAIG,EAAG,KAAAH,OAAIsH,GAE1BhG,YAAWA,IACF,EAETL,KAAM,CACJpB,aAAc,EACdD,cAAe,EACfK,UAAWA,IAAM,GAEnBiB,KAAM,CACJrB,aAAcsD,OAAOC,iBACrBxD,cAAe,EACfK,UAAWA,IAAM,GAEnBF,SAAQA,IACC,GAAPC,OAAU+U,EAAG,KAAA/U,OAAIG,EAAG,KAAAH,OAAIsH,KAI9B+N,EACAlV,EACAmH,EACAvC,E,CAGN,CAEA,gBAAMkO,CAAUvO,GAA4C,IAA3C,MAAE/B,GAAyC+B,EAC1D,IAAK/B,EAAM+G,OACT,MAAM,IAAI3I,MAAM,mCAElB,MAAO,CAAE0J,KAAM9H,EAAM+G,OAAQqJ,WAAY,GAAIC,WAAY,GAAIrQ,QAC/D,CAEA,eAAM2R,GAA6B,IAAnBvP,EAAAzE,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAiB,CAAC,EAChC,MAAM2X,EAAM,GAAHjY,OAAMF,KAAKgZ,QAAO,KAAA9Y,OAAIF,KAAKiZ,QAAO,kCACrCE,QAAeV,MAAMN,EAAKlT,GAChC,IAAKkU,EAAOT,GACV,MAAM,IAAIzX,MAAM,QAADf,OACLiZ,EAAOR,OAAM,cAAAzY,OAAaiY,EAAG,MAAAjY,aAAWiZ,EAAOjI,SAG3D,MAAMvG,QAAawO,EAAOC,OACpBlF,QAAchU,EAAOyK,EAAK4H,OAAO8G,KAAMpU,GAE7C,GAAIiP,EAAMvO,YAAY,KAAO6L,EAC3B,MAAM,IAAIvQ,MAAM,kBAElB,MAAMkT,EAAUD,EAAMvO,YAAY,GAE5B2T,EAAYrI,EADCiD,EAAMjU,SAAS,OAAQ,EAAG,EAAIkU,IAK3CoF,EAAkD,GAClDC,EAAmC,CAAC,EACpCC,EAAUH,EAAUrN,QAAO7B,GAAe,OAAVA,EAAEoD,MACxC,IAAK,MAAOxI,EAAO0U,KAAWD,EAAQjD,UAAW,CAC/C,IAAI9R,EAAU,GACVjE,EAAS,EACb,IAAK,MAAMkZ,KAAQD,EAAO/O,KACP,OAAbgP,EAAKnM,IACP9I,EAAUiV,EAAKjM,MACO,OAAbiM,EAAKnM,MACd/M,GAAUkZ,EAAKjM,OAGnB8L,EAAS9U,GAAWM,EACpBuU,EAASvU,GAAS,CAAEN,UAASjE,S,CAI/B,OAFAT,KAAKqU,WAAamF,EAClBxZ,KAAKsU,WAAaiF,EACXD,CACT,E,wBC3JF,IAAIM,EAAmB5Z,MAAQA,KAAK4Z,iBAAoB,SAAUC,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,EACxD,EACA/N,OAAOiO,eAAeC,EAAS,aAAc,CAAEtM,OAAO,IACtD,MAAMuM,EAA6BC,EAAQ,OACrCC,EAA6BP,EAAgBM,EAAQ,QACrDE,EAA4BR,EAAgBM,EAAQ,QAC1D,MAAMvH,EACF9S,WAAAA,CAAW+E,GAAmB,IAAlB,KAAEmO,EAAI,MAAEH,GAAQhO,EACxB,GAAoB,oBAATmO,EACP,MAAM,IAAIsH,UAAU,6BAExB,GAAqB,kBAAVzH,EACP,MAAM,IAAIyH,UAAU,4BAExB,GAAyB,oBAAdzH,EAAMzH,KACQ,oBAAdyH,EAAMsE,KACW,oBAAjBtE,EAAM0H,OACb,MAAM,IAAID,UAAU,qEAExBra,KAAK4S,MAAQA,EACb5S,KAAKua,aAAexH,CACxB,CACA,uBAAOyH,CAAiBC,GACpB,MAEmB,eAAnBA,EAAUxN,MAGa,gBAAnBwN,EAAUtY,MAEY,wBAAtBsY,EAAUC,SAEY,mBAAtBD,EAAUC,OAClB,CACAC,KAAAA,CAAMC,EAAKC,GACH7a,KAAK4S,MAAMzH,IAAIyP,KAASC,GACxB7a,KAAK4S,MAAM0H,OAAOM,EAE1B,CACA7H,IAAAA,CAAK6H,EAAKjQ,EAAM5I,EAAQ+Y,GACpB,MAAMC,EAAU,IAAIZ,EAA2Ba,QACzCC,EAAiB,IAAIb,EAA0BY,QACrDC,EAAeC,YAAYJ,GAC3B,MAAMK,EAAW,CACbJ,QAASA,EACTK,QAASpb,KAAKua,aAAa5P,EAAMoQ,EAAQhZ,QAAS2Y,IAC9CO,EAAeI,SAASX,EAAQ,IAEpCY,SAAS,EACTL,iBACA,WAAIjZ,GACA,OAAOhC,KAAK+a,QAAQhZ,OAAOC,OAC/B,GAEJmZ,EAASJ,QAAQQ,UAAUxZ,GAE3BoZ,EAASJ,QAAQhZ,OAAOyZ,iBAAiB,SAAS,KACzCL,EAASG,SACVtb,KAAK2a,MAAMC,EAAKO,EACpB,IAGJA,EAASC,QACJK,MAAK,KACNN,EAASG,SAAU,CAAI,IACxB,KACCH,EAASG,SAAU,EAEnBtb,KAAK2a,MAAMC,EAAKO,EAAS,IAExB9S,OAAMnG,IAIP,MADAkM,QAAQsN,MAAMxZ,GACRA,CAAC,IAEXlC,KAAK4S,MAAMsE,IAAI0D,EAAKO,EACxB,CACA,yBAAOQ,CAAmBP,EAASrZ,GAI/B,SAAS6Z,IACL,GAAI7Z,GAAUA,EAAOC,QACjB,MAAM8J,OAAO+P,OAAO,IAAI5a,MAAM,WAAY,CAAEkB,KAAM,eAE1D,CACA,OAAOiZ,EAAQK,MAAKtC,IAChByC,IACOzC,KACRuC,IAEC,MADAE,IACMF,CAAK,GAEnB,CACAzE,GAAAA,CAAI2D,GACA,OAAO5a,KAAK4S,MAAMqE,IAAI2D,EAC1B,CAaAzP,GAAAA,CAAIyP,EAAKjQ,EAAM5I,EAAQ+Y,GACnB,IAAK/Y,GAAU4I,aAAgBsP,EAA2B6B,YACtD,MAAM,IAAIzB,UAAU,yGAExB,MAAM0B,EAAa/b,KAAK4S,MAAMzH,IAAIyP,GAClC,OAAImB,EACIA,EAAW/Z,UAAY+Z,EAAWT,SAElCtb,KAAK2a,MAAMC,EAAKmB,GACT/b,KAAKmL,IAAIyP,EAAKjQ,EAAM5I,EAAQ+Y,IAEnCiB,EAAWT,QAEJS,EAAWX,SAItBW,EAAWhB,QAAQQ,UAAUxZ,GAC7Bga,EAAWd,eAAeC,YAAYJ,GAC/BnI,EAAsBgJ,mBAAmBI,EAAWX,QAASrZ,KAGxE/B,KAAK+S,KAAK6H,EAAKjQ,EAAM5I,EAAQ+Y,GACtBnI,EAAsBgJ,mBAG7B3b,KAAK4S,MAAMzH,IAAIyP,GAAKQ,QAASrZ,GACjC,CAOAuY,OAAOM,GACH,MAAMoB,EAAchc,KAAK4S,MAAMzH,IAAIyP,GAC/BoB,IACKA,EAAYV,SACbU,EAAYjB,QAAQkB,QAExBjc,KAAK4S,MAAM0H,OAAOM,GAE1B,CAKAsB,KAAAA,GAEI,MAAMC,EAAUnc,KAAK4S,MAAM7G,OAC3B,IAAIqQ,EAAc,EAClB,IAAK,IAAIjD,EAASgD,EAAQE,QAASlD,EAAOvD,KAAMuD,EAASgD,EAAQE,OAC7Drc,KAAKsa,OAAOnB,EAAOzL,OACnB0O,GAAe,EAEnB,OAAOA,CACX,EAEJpC,EAAAA,QAAkBrH,C,kBCzKlB7G,OAAOiO,eAAeC,EAAS,aAAc,CAAEtM,OAAO,IACtD,MAAMuM,EAA6BC,EAAQ,OAC3C,MAAMoC,GAgDNtC,EAAAA,QA1CA,MACIna,WAAAA,GACIG,KAAKuc,QAAU,IAAIC,IACnBxc,KAAKyc,gBAAkB,IAAIxC,EAA2ByC,eAC1D,CAOAnB,SAAAA,GAAqC,IAA3BxZ,EAAMvB,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAG,IAAI8b,EACnB,GAAItc,KAAK+B,OAAOC,QACZ,MAAM,IAAIf,MAAM,yCAIpBjB,KAAKuc,QAAQI,IAAI5a,GACbA,EAAOC,QAGPhC,KAAK4c,cAAc7a,GAEqB,oBAA5BA,EAAOyZ,kBACnBzZ,EAAOyZ,iBAAiB,SAAS,KAC7Bxb,KAAK4c,cAAc7a,EAAO,GAGtC,CACA6a,aAAAA,CAAc7a,GACV/B,KAAKuc,QAAQjC,OAAOvY,GACM,IAAtB/B,KAAKuc,QAAQ3H,MACb5U,KAAKyc,gBAAgBR,OAE7B,CACA,UAAIla,GACA,OAAO/B,KAAKyc,gBAAgB1a,MAChC,CACAka,KAAAA,GACIjc,KAAKyc,gBAAgBR,OACzB,E,gBChDJnQ,OAAOiO,eAAeC,EAAS,aAAc,CAAEtM,OAAO,IAgBtDsM,EAAAA,QAfA,MACIna,WAAAA,GACIG,KAAK6c,UAAY,IAAIL,GACzB,CACAtB,WAAAA,GAAkC,IAAtBG,EAAQ7a,UAAAC,OAAA,QAAAO,IAAAR,UAAA,GAAAA,UAAA,GAAG,OACnBR,KAAK6c,UAAUF,IAAItB,GACnBA,EAASrb,KAAK8c,eAClB,CACAzB,QAAAA,CAASX,GACL1a,KAAK8c,eAAiBpC,EACtB1a,KAAK6c,UAAUE,SAAQlE,IACnBA,EAAI6B,EAAQ,GAEpB,E,kBCbJ5O,OAAOiO,eAAeC,EAAS,aAAc,CAAEtM,OAAO,IACtDsM,EAAQ8B,YAAc9B,EAAQ0C,qBAAkB,EAChD,MAAMM,EAAiB9C,EAAQ,OAC/B,IAAI+C,EAAY,WAIZ,GAAoB,qBAATC,KACP,OAAOA,KAEX,GAAsB,qBAAXC,OACP,OAAOA,OAEX,GAAsB,qBAAXC,EAAAA,EACP,OAAOA,EAAAA,EAEX,MAAM,IAAInc,MAAM,iCACpB,EAEA,IAAIyb,EAAyD,qBAAhCO,IAAYP,gBAAkCM,EAAeN,gBAAkBO,IAAYP,gBACxH1C,EAAQ0C,gBAAkBA,EAE1B,IAAIZ,EAAqD,qBAAhCmB,IAAYP,gBAAkCM,EAAelB,YAAcmB,IAAYnB,YAChH9B,EAAQ8B,YAAcA,C,wBCxBtB,IAAIlC,EAAmB5Z,MAAQA,KAAK4Z,iBAAoB,SAAUC,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,EACxD,EACA/N,OAAOiO,eAAeC,EAAS,aAAc,CAAEtM,OAAO,IACtD,MAAM2P,EAA0BzD,EAAgBM,EAAQ,QACxDF,EAAAA,QAAkBqD,EAAwBrC,O","sources":["../../../node_modules/@gmod/bam/src/virtualOffset.ts","../../../node_modules/@gmod/bam/src/chunk.ts","../../../node_modules/@gmod/bam/src/util.ts","../../../node_modules/@gmod/bam/src/indexFile.ts","../../../node_modules/@gmod/bam/src/bai.ts","../../../node_modules/@gmod/bam/src/csi.ts","../../../node_modules/@gmod/bam/src/constants.ts","../../../node_modules/@gmod/bam/src/record.ts","../../../node_modules/@gmod/bam/src/sam.ts","../../../node_modules/@gmod/bam/src/bamFile.ts","../../../node_modules/@gmod/bam/src/htsget.ts","../../../node_modules/abortable-promise-cache/esm/AbortablePromiseCache.js","../../../node_modules/abortable-promise-cache/esm/AggregateAbortController.js","../../../node_modules/abortable-promise-cache/esm/AggregateStatusReporter.js","../../../node_modules/abortable-promise-cache/esm/abortcontroller-ponyfill.js","../../../node_modules/abortable-promise-cache/esm/index.js"],"sourcesContent":["export default class VirtualOffset {\n  public blockPosition: number\n  public dataPosition: number\n  constructor(blockPosition: number, dataPosition: number) {\n    this.blockPosition = blockPosition // < offset of the compressed data block\n    this.dataPosition = dataPosition // < offset into the uncompressed data\n  }\n\n  toString() {\n    return `${this.blockPosition}:${this.dataPosition}`\n  }\n\n  compareTo(b: VirtualOffset) {\n    return (\n      this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition\n    )\n  }\n\n  static min(...args: VirtualOffset[]) {\n    let min\n    let i = 0\n    for (; !min; i += 1) {\n      min = args[i]\n    }\n    for (; i < args.length; i += 1) {\n      if (min.compareTo(args[i]) > 0) {\n        min = args[i]\n      }\n    }\n    return min\n  }\n}\nexport function fromBytes(bytes: Buffer, offset = 0, bigendian = false) {\n  if (bigendian) {\n    throw new Error('big-endian virtual file offsets not implemented')\n  }\n\n  return new VirtualOffset(\n    bytes[offset + 7] * 0x10000000000 +\n      bytes[offset + 6] * 0x100000000 +\n      bytes[offset + 5] * 0x1000000 +\n      bytes[offset + 4] * 0x10000 +\n      bytes[offset + 3] * 0x100 +\n      bytes[offset + 2],\n    (bytes[offset + 1] << 8) | bytes[offset],\n  )\n}\n","import VirtualOffset from './virtualOffset'\n\n// little class representing a chunk in the index\nexport default class Chunk {\n  public buffer?: Buffer\n\n  constructor(\n    public minv: VirtualOffset,\n    public maxv: VirtualOffset,\n    public bin: number,\n    public _fetchedSize?: number,\n  ) {}\n\n  toUniqueString() {\n    return `${this.minv}..${this.maxv} (bin ${\n      this.bin\n    }, fetchedSize ${this.fetchedSize()})`\n  }\n\n  toString() {\n    return this.toUniqueString()\n  }\n\n  compareTo(b: Chunk) {\n    return (\n      this.minv.compareTo(b.minv) ||\n      this.maxv.compareTo(b.maxv) ||\n      this.bin - b.bin\n    )\n  }\n\n  fetchedSize() {\n    if (this._fetchedSize !== undefined) {\n      return this._fetchedSize\n    }\n    return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition\n  }\n}\n","import Long from 'long'\nimport Chunk from './chunk'\nimport VirtualOffset from './virtualOffset'\n\nexport function timeout(ms: number) {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n\nexport function longToNumber(long: Long) {\n  if (\n    long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n    long.lessThan(Number.MIN_SAFE_INTEGER)\n  ) {\n    throw new Error('integer overflow')\n  }\n  return long.toNumber()\n}\n\n/**\n * Properly check if the given AbortSignal is aborted.\n * Per the standard, if the signal reads as aborted,\n * this function throws either a DOMException AbortError, or a regular error\n * with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nexport function checkAbortSignal(signal?: AbortSignal) {\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    // console.log('bam aborted!')\n    if (typeof DOMException === 'undefined') {\n      const e = new Error('aborted')\n      //@ts-ignore\n      e.code = 'ERR_ABORTED'\n      throw e\n    } else {\n      throw new DOMException('aborted', 'AbortError')\n    }\n  }\n}\n\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal?: AbortSignal) {\n  await Promise.resolve()\n  checkAbortSignal(signal)\n}\n\nexport function canMergeBlocks(chunk1: Chunk, chunk2: Chunk) {\n  return (\n    chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n    chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000\n  )\n}\n\nexport interface BamOpts {\n  viewAsPairs?: boolean\n  pairAcrossChr?: boolean\n  maxInsertSize?: number\n  signal?: AbortSignal\n}\n\nexport interface BaseOpts {\n  signal?: AbortSignal\n}\n\nexport function makeOpts(obj: AbortSignal | BaseOpts = {}): BaseOpts {\n  return 'aborted' in obj ? ({ signal: obj } as BaseOpts) : (obj as BaseOpts)\n}\n\nexport function optimizeChunks(chunks: Chunk[], lowest?: VirtualOffset) {\n  const mergedChunks: Chunk[] = []\n  let lastChunk: Chunk | undefined\n\n  if (chunks.length === 0) {\n    return chunks\n  }\n\n  chunks.sort((c0, c1) => {\n    const dif = c0.minv.blockPosition - c1.minv.blockPosition\n    return dif === 0 ? c0.minv.dataPosition - c1.minv.dataPosition : dif\n  })\n\n  for (const chunk of chunks) {\n    if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n      if (lastChunk === undefined) {\n        mergedChunks.push(chunk)\n        lastChunk = chunk\n      } else {\n        if (canMergeBlocks(lastChunk, chunk)) {\n          if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n            lastChunk.maxv = chunk.maxv\n          }\n        } else {\n          mergedChunks.push(chunk)\n          lastChunk = chunk\n        }\n      }\n    }\n  }\n\n  return mergedChunks\n}\n\nexport function parsePseudoBin(bytes: Buffer, offset: number) {\n  const lineCount = longToNumber(\n    Long.fromBytesLE(\n      Array.prototype.slice.call(bytes, offset, offset + 8),\n      true,\n    ),\n  )\n  return { lineCount }\n}\n\nexport function findFirstData(\n  firstDataLine: VirtualOffset | undefined,\n  virtualOffset: VirtualOffset,\n) {\n  return firstDataLine\n    ? firstDataLine.compareTo(virtualOffset) > 0\n      ? virtualOffset\n      : firstDataLine\n    : virtualOffset\n}\n\nexport function parseNameBytes(\n  namesBytes: Buffer,\n  renameRefSeq: (arg: string) => string = s => s,\n) {\n  let currRefId = 0\n  let currNameStart = 0\n  const refIdToName = []\n  const refNameToId: { [key: string]: number } = {}\n  for (let i = 0; i < namesBytes.length; i += 1) {\n    if (!namesBytes[i]) {\n      if (currNameStart < i) {\n        let refName = namesBytes.toString('utf8', currNameStart, i)\n        refName = renameRefSeq(refName)\n        refIdToName[currRefId] = refName\n        refNameToId[refName] = currRefId\n      }\n      currNameStart = i + 1\n      currRefId += 1\n    }\n  }\n  return { refNameToId, refIdToName }\n}\n","import { GenericFilehandle } from 'generic-filehandle'\nimport Chunk from './chunk'\nimport { BaseOpts } from './util'\n\nexport default abstract class IndexFile {\n  public filehandle: GenericFilehandle\n  public renameRefSeq: (s: string) => string\n\n  /**\n   * @param {filehandle} filehandle\n   * @param {function} [renameRefSeqs]\n   */\n  constructor({\n    filehandle,\n    renameRefSeq = (n: string) => n,\n  }: {\n    filehandle: GenericFilehandle\n    renameRefSeq?: (a: string) => string\n  }) {\n    this.filehandle = filehandle\n    this.renameRefSeq = renameRefSeq\n  }\n  public abstract lineCount(refId: number): Promise<number>\n  public abstract indexCov(\n    refId: number,\n    start?: number,\n    end?: number,\n  ): Promise<{ start: number; end: number; score: number }[]>\n\n  public abstract blocksForRange(\n    chrId: number,\n    start: number,\n    end: number,\n    opts?: BaseOpts,\n  ): Promise<Chunk[]>\n}\n","import VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\n\nimport { optimizeChunks, parsePseudoBin, findFirstData, BaseOpts } from './util'\nimport IndexFile from './indexFile'\n\nconst BAI_MAGIC = 21578050 // BAI\\1\n\nfunction roundDown(n: number, multiple: number) {\n  return n - (n % multiple)\n}\nfunction roundUp(n: number, multiple: number) {\n  return n - (n % multiple) + multiple\n}\n\nfunction reg2bins(beg: number, end: number) {\n  end -= 1\n  return [\n    [0, 0],\n    [1 + (beg >> 26), 1 + (end >> 26)],\n    [9 + (beg >> 23), 9 + (end >> 23)],\n    [73 + (beg >> 20), 73 + (end >> 20)],\n    [585 + (beg >> 17), 585 + (end >> 17)],\n    [4681 + (beg >> 14), 4681 + (end >> 14)],\n  ]\n}\n\nexport default class BAI extends IndexFile {\n  public setupP?: ReturnType<BAI['_parse']>\n\n  async lineCount(refId: number, opts?: BaseOpts) {\n    const indexData = await this.parse(opts)\n    return indexData.indices[refId]?.stats?.lineCount || 0\n  }\n\n  // fetch and parse the index\n  async _parse(opts?: BaseOpts) {\n    const bytes = (await this.filehandle.readFile(opts)) as Buffer\n\n    // check BAI magic numbers\n    if (bytes.readUInt32LE(0) !== BAI_MAGIC) {\n      throw new Error('Not a BAI file')\n    }\n\n    const refCount = bytes.readInt32LE(4)\n    const depth = 5\n    const binLimit = ((1 << ((depth + 1) * 3)) - 1) / 7\n\n    // read the indexes for each reference sequence\n    let curr = 8\n    let firstDataLine: VirtualOffset | undefined\n\n    type BinIndex = { [key: string]: Chunk[] }\n    type LinearIndex = VirtualOffset[]\n    const indices = new Array<{\n      binIndex: BinIndex\n      linearIndex: LinearIndex\n      stats?: { lineCount: number }\n    }>(refCount)\n    for (let i = 0; i < refCount; i++) {\n      // the binning index\n      const binCount = bytes.readInt32LE(curr)\n      let stats\n\n      curr += 4\n      const binIndex: { [key: number]: Chunk[] } = {}\n\n      for (let j = 0; j < binCount; j += 1) {\n        const bin = bytes.readUInt32LE(curr)\n        curr += 4\n        if (bin === binLimit + 1) {\n          curr += 4\n          stats = parsePseudoBin(bytes, curr + 16)\n          curr += 32\n        } else if (bin > binLimit + 1) {\n          throw new Error('bai index contains too many bins, please use CSI')\n        } else {\n          const chunkCount = bytes.readInt32LE(curr)\n          curr += 4\n          const chunks = new Array<Chunk>(chunkCount)\n          for (let k = 0; k < chunkCount; k++) {\n            const u = fromBytes(bytes, curr)\n            curr += 8\n            const v = fromBytes(bytes, curr)\n            curr += 8\n            firstDataLine = findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      const linearCount = bytes.readInt32LE(curr)\n      curr += 4\n      // as we're going through the linear index, figure out the smallest\n      // virtual offset in the indexes, which tells us where the BAM header\n      // ends\n      const linearIndex = new Array<VirtualOffset>(linearCount)\n      for (let j = 0; j < linearCount; j++) {\n        const offset = fromBytes(bytes, curr)\n        curr += 8\n        firstDataLine = findFirstData(firstDataLine, offset)\n        linearIndex[j] = offset\n      }\n\n      indices[i] = { binIndex, linearIndex, stats }\n    }\n\n    return {\n      bai: true,\n      firstDataLine,\n      maxBlockSize: 1 << 16,\n      indices,\n      refCount,\n    }\n  }\n\n  async indexCov(\n    seqId: number,\n    start?: number,\n    end?: number,\n    opts: BaseOpts = {},\n  ): Promise<{ start: number; end: number; score: number }[]> {\n    const v = 16384\n    const range = start !== undefined\n    const indexData = await this.parse(opts)\n    const seqIdx = indexData.indices[seqId]\n    if (!seqIdx) {\n      return []\n    }\n    const { linearIndex = [], stats } = seqIdx\n    if (linearIndex.length === 0) {\n      return []\n    }\n    const e = end === undefined ? (linearIndex.length - 1) * v : roundUp(end, v)\n    const s = start === undefined ? 0 : roundDown(start, v)\n    const depths = range\n      ? new Array((e - s) / v)\n      : new Array(linearIndex.length - 1)\n    const totalSize = linearIndex[linearIndex.length - 1].blockPosition\n    if (e > (linearIndex.length - 1) * v) {\n      throw new Error('query outside of range of linear index')\n    }\n    let currentPos = linearIndex[s / v].blockPosition\n    for (let i = s / v, j = 0; i < e / v; i++, j++) {\n      depths[j] = {\n        score: linearIndex[i + 1].blockPosition - currentPos,\n        start: i * v,\n        end: i * v + v,\n      }\n      currentPos = linearIndex[i + 1].blockPosition\n    }\n    return depths.map(d => ({\n      ...d,\n      score: (d.score * (stats?.lineCount || 0)) / totalSize,\n    }))\n  }\n\n  async blocksForRange(\n    refId: number,\n    min: number,\n    max: number,\n    opts: BaseOpts = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    if (!indexData) {\n      return []\n    }\n    const ba = indexData.indices[refId]\n    if (!ba) {\n      return []\n    }\n\n    // List of bin #s that overlap min, max\n    const overlappingBins = reg2bins(min, max)\n    const chunks: Chunk[] = []\n\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          const binChunks = ba.binIndex[bin]\n          for (const binChunk of binChunks) {\n            chunks.push(binChunk)\n          }\n        }\n      }\n    }\n\n    // Use the linear index to find minimum file position of chunks that could\n    // contain alignments in the region\n    const nintv = ba.linearIndex.length\n    let lowest: VirtualOffset | undefined\n    const minLin = Math.min(min >> 14, nintv - 1)\n    const maxLin = Math.min(max >> 14, nintv - 1)\n    for (let i = minLin; i <= maxLin; ++i) {\n      const vp = ba.linearIndex[i]\n      if (vp && (!lowest || vp.compareTo(lowest) < 0)) {\n        lowest = vp\n      }\n    }\n\n    return optimizeChunks(chunks, lowest)\n  }\n\n  async parse(opts: BaseOpts = {}) {\n    if (!this.setupP) {\n      this.setupP = this._parse(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n\n  async hasRefSeq(seqId: number, opts: BaseOpts = {}) {\n    const header = await this.parse(opts)\n    return !!header.indices[seqId]?.binIndex\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\nimport VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\nimport {\n  optimizeChunks,\n  findFirstData,\n  parsePseudoBin,\n  parseNameBytes,\n  BaseOpts,\n} from './util'\n\nimport IndexFile from './indexFile'\n\nconst CSI1_MAGIC = 21582659 // CSI\\1\nconst CSI2_MAGIC = 38359875 // CSI\\2\n\nfunction lshift(num: number, bits: number) {\n  return num * 2 ** bits\n}\nfunction rshift(num: number, bits: number) {\n  return Math.floor(num / 2 ** bits)\n}\n\nexport default class CSI extends IndexFile {\n  private maxBinNumber = 0\n  private depth = 0\n  private minShift = 0\n\n  public setupP?: ReturnType<CSI['_parse']>\n\n  async lineCount(refId: number, opts?: BaseOpts) {\n    const indexData = await this.parse(opts)\n    return indexData.indices[refId]?.stats?.lineCount || 0\n  }\n\n  async indexCov() {\n    return []\n  }\n\n  parseAuxData(bytes: Buffer, offset: number) {\n    const formatFlags = bytes.readInt32LE(offset)\n    const coordinateType =\n      formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed'\n    const format = (\n      { 0: 'generic', 1: 'SAM', 2: 'VCF' } as {\n        [key: number]: string\n      }\n    )[formatFlags & 0xf]\n    if (!format) {\n      throw new Error(`invalid Tabix preset format flags ${formatFlags}`)\n    }\n    const columnNumbers = {\n      ref: bytes.readInt32LE(offset + 4),\n      start: bytes.readInt32LE(offset + 8),\n      end: bytes.readInt32LE(offset + 12),\n    }\n    const metaValue = bytes.readInt32LE(offset + 16)\n    const metaChar = metaValue ? String.fromCharCode(metaValue) : ''\n    const skipLines = bytes.readInt32LE(offset + 20)\n    const nameSectionLength = bytes.readInt32LE(offset + 24)\n\n    return {\n      columnNumbers,\n      coordinateType,\n      metaValue,\n      metaChar,\n      skipLines,\n      format,\n      formatFlags,\n      ...parseNameBytes(\n        bytes.subarray(offset + 28, offset + 28 + nameSectionLength),\n        this.renameRefSeq,\n      ),\n    }\n  }\n\n  // fetch and parse the index\n  async _parse(opts: { signal?: AbortSignal }) {\n    const buffer = await this.filehandle.readFile(opts)\n    const bytes = await unzip(buffer)\n\n    let csiVersion\n    // check TBI magic numbers\n    if (bytes.readUInt32LE(0) === CSI1_MAGIC) {\n      csiVersion = 1\n    } else if (bytes.readUInt32LE(0) === CSI2_MAGIC) {\n      csiVersion = 2\n    } else {\n      throw new Error('Not a CSI file')\n      // TODO: do we need to support big-endian CSI files?\n    }\n\n    this.minShift = bytes.readInt32LE(4)\n    this.depth = bytes.readInt32LE(8)\n    this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7\n    const auxLength = bytes.readInt32LE(12)\n    const aux = auxLength >= 30 ? this.parseAuxData(bytes, 16) : undefined\n    const refCount = bytes.readInt32LE(16 + auxLength)\n\n    type BinIndex = { [key: string]: Chunk[] }\n\n    // read the indexes for each reference sequence\n    let curr = 16 + auxLength + 4\n    let firstDataLine: VirtualOffset | undefined\n    const indices = new Array<{\n      binIndex: BinIndex\n      stats?: { lineCount: number }\n    }>(refCount)\n    for (let i = 0; i < refCount; i++) {\n      // the binning index\n      const binCount = bytes.readInt32LE(curr)\n      curr += 4\n      const binIndex: { [key: string]: Chunk[] } = {}\n      let stats // < provided by parsing a pseudo-bin, if present\n      for (let j = 0; j < binCount; j++) {\n        const bin = bytes.readUInt32LE(curr)\n        curr += 4\n        if (bin > this.maxBinNumber) {\n          stats = parsePseudoBin(bytes, curr + 28)\n          curr += 28 + 16\n        } else {\n          firstDataLine = findFirstData(firstDataLine, fromBytes(bytes, curr))\n          curr += 8\n          const chunkCount = bytes.readInt32LE(curr)\n          curr += 4\n          const chunks = new Array<Chunk>(chunkCount)\n          for (let k = 0; k < chunkCount; k += 1) {\n            const u = fromBytes(bytes, curr)\n            curr += 8\n            const v = fromBytes(bytes, curr)\n            curr += 8\n            firstDataLine = findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      indices[i] = { binIndex, stats }\n    }\n\n    return {\n      csiVersion,\n      firstDataLine,\n      indices,\n      refCount,\n      csi: true,\n      maxBlockSize: 1 << 16,\n      ...aux,\n    }\n  }\n\n  async blocksForRange(\n    refId: number,\n    min: number,\n    max: number,\n    opts: BaseOpts = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    const ba = indexData?.indices[refId]\n    if (!ba) {\n      return []\n    }\n    const overlappingBins = this.reg2bins(min, max)\n\n    if (overlappingBins.length === 0) {\n      return []\n    }\n\n    const chunks = []\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          const binChunks = ba.binIndex[bin]\n          for (const c of binChunks) {\n            chunks.push(c)\n          }\n        }\n      }\n    }\n\n    return optimizeChunks(chunks, new VirtualOffset(0, 0))\n  }\n\n  /**\n   * calculate the list of bins that may overlap with region [beg,end)\n   * (zero-based half-open)\n   */\n  reg2bins(beg: number, end: number) {\n    beg -= 1 // < convert to 1-based closed\n    if (beg < 1) {\n      beg = 1\n    }\n    if (end > 2 ** 50) {\n      end = 2 ** 34\n    } // 17 GiB ought to be enough for anybody\n    end -= 1\n    let l = 0\n    let t = 0\n    let s = this.minShift + this.depth * 3\n    const bins = []\n    for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n      const b = t + rshift(beg, s)\n      const e = t + rshift(end, s)\n      if (e - b + bins.length > this.maxBinNumber) {\n        throw new Error(\n          `query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`,\n        )\n      }\n      bins.push([b, e])\n    }\n    return bins\n  }\n\n  async parse(opts: BaseOpts = {}) {\n    if (!this.setupP) {\n      this.setupP = this._parse(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n\n  async hasRefSeq(seqId: number, opts: BaseOpts = {}) {\n    const header = await this.parse(opts)\n    return !!header.indices[seqId]?.binIndex\n  }\n}\n","export default {\n  //  the read is paired in sequencing, no matter whether it is mapped in a pair\n  BAM_FPAIRED: 1,\n  //  the read is mapped in a proper pair\n  BAM_FPROPER_PAIR: 2,\n  //  the read itself is unmapped; conflictive with BAM_FPROPER_PAIR\n  BAM_FUNMAP: 4,\n  //  the mate is unmapped\n  BAM_FMUNMAP: 8,\n  //  the read is mapped to the reverse strand\n  BAM_FREVERSE: 16,\n  //  the mate is mapped to the reverse strand\n  BAM_FMREVERSE: 32,\n  //  this is read1\n  BAM_FREAD1: 64,\n  //  this is read2\n  BAM_FREAD2: 128,\n  //  not primary alignment\n  BAM_FSECONDARY: 256,\n  //  QC failure\n  BAM_FQCFAIL: 512,\n  //  optical or PCR duplicate\n  BAM_FDUP: 1024,\n  //  supplementary alignment\n  BAM_FSUPPLEMENTARY: 2048,\n}\n","/* eslint-disable @typescript-eslint/no-empty-function */\nimport Constants from './constants'\n\nconst SEQRET_DECODER = '=ACMGRSVTWYHKDBN'.split('')\nconst CIGAR_DECODER = 'MIDNSHP=X???????'.split('')\n\n/**\n * Class of each BAM record returned by this API.\n */\nexport default class BamRecord {\n  private data = {} as { [key: string]: any }\n  private bytes: { start: number; end: number; byteArray: Buffer }\n  private _id: number\n  private _tagOffset: number | undefined\n  private _tagList: string[] = []\n  private _allTagsParsed = false\n\n  public flags: any\n  public _refID: number\n  constructor(args: any) {\n    const { bytes, fileOffset } = args\n    const { byteArray, start } = bytes\n    this.data = {}\n    this.bytes = bytes\n    this._id = fileOffset\n    this._refID = byteArray.readInt32LE(start + 4)\n    this.data.start = byteArray.readInt32LE(start + 8)\n    this.flags = (byteArray.readInt32LE(start + 16) & 0xffff0000) >> 16\n  }\n\n  get(field: string) {\n    //@ts-ignore\n    if (this[field]) {\n      //@ts-ignore\n      if (this.data[field]) {\n        return this.data[field]\n      }\n      //@ts-ignore\n      this.data[field] = this[field]()\n      return this.data[field]\n    }\n    return this._get(field.toLowerCase())\n  }\n\n  end() {\n    return this.get('start') + this.get('length_on_ref')\n  }\n\n  seq_id() {\n    return this._refID\n  }\n\n  // same as get(), except requires lower-case arguments.  used\n  // internally to save lots of calls to field.toLowerCase()\n  _get(field: string) {\n    if (field in this.data) {\n      return this.data[field]\n    }\n    this.data[field] = this._parseTag(field)\n    return this.data[field]\n  }\n\n  _tags() {\n    this._parseAllTags()\n\n    let tags = ['seq']\n\n    if (!this.isSegmentUnmapped()) {\n      tags.push(\n        'start',\n        'end',\n        'strand',\n        'score',\n        'qual',\n        'MQ',\n        'CIGAR',\n        'length_on_ref',\n        'template_length',\n      )\n    }\n    if (this.isPaired()) {\n      tags.push('next_segment_position', 'pair_orientation')\n    }\n    tags = tags.concat(this._tagList || [])\n\n    for (const k of Object.keys(this.data)) {\n      if (k[0] !== '_' && k !== 'next_seq_id') {\n        tags.push(k)\n      }\n    }\n\n    const seen: { [key: string]: boolean } = {}\n    return tags.filter(t => {\n      if (\n        (t in this.data && this.data[t] === undefined) ||\n        t === 'CG' ||\n        t === 'cg'\n      ) {\n        return false\n      }\n\n      const lt = t.toLowerCase()\n      const s = seen[lt]\n      seen[lt] = true\n      return !s\n    })\n  }\n\n  parent() {\n    return\n  }\n\n  children() {\n    return this.get('subfeatures')\n  }\n\n  id() {\n    return this._id\n  }\n\n  // special parsers\n  /**\n   * Mapping quality score.\n   */\n  mq() {\n    const mq = (this.get('_bin_mq_nl') & 0xff00) >> 8\n    return mq === 255 ? undefined : mq\n  }\n\n  score() {\n    return this.get('mq')\n  }\n\n  qual() {\n    return this.qualRaw()?.join(' ')\n  }\n\n  qualRaw() {\n    if (this.isSegmentUnmapped()) {\n      return\n    }\n\n    const { start, byteArray } = this.bytes\n    const p =\n      start +\n      36 +\n      this.get('_l_read_name') +\n      this.get('_n_cigar_op') * 4 +\n      this.get('_seq_bytes')\n    const lseq = this.get('seq_length')\n    return byteArray.subarray(p, p + lseq)\n  }\n\n  strand() {\n    return this.isReverseComplemented() ? -1 : 1\n  }\n\n  multi_segment_next_segment_strand() {\n    if (this.isMateUnmapped()) {\n      return\n    }\n    return this.isMateReverseComplemented() ? -1 : 1\n  }\n\n  name() {\n    return this.get('_read_name')\n  }\n\n  _read_name() {\n    const nl = this.get('_l_read_name')\n    const { byteArray, start } = this.bytes\n    return byteArray.toString('ascii', start + 36, start + 36 + nl - 1)\n  }\n\n  /**\n   * Get the value of a tag, parsing the tags as far as necessary.\n   * Only called if we have not already parsed that field.\n   */\n  _parseTag(tagName?: string) {\n    // if all of the tags have been parsed and we're still being\n    // called, we already know that we have no such tag, because\n    // it would already have been cached.\n    if (this._allTagsParsed) {\n      return\n    }\n\n    const { byteArray, start } = this.bytes\n    let p =\n      this._tagOffset ||\n      start +\n        36 +\n        this.get('_l_read_name') +\n        this.get('_n_cigar_op') * 4 +\n        this.get('_seq_bytes') +\n        this.get('seq_length')\n\n    const blockEnd = this.bytes.end\n    let lcTag\n    while (p < blockEnd && lcTag !== tagName) {\n      const tag = String.fromCharCode(byteArray[p], byteArray[p + 1])\n      lcTag = tag.toLowerCase()\n      const type = String.fromCharCode(byteArray[p + 2])\n      p += 3\n\n      let value\n      switch (type) {\n        case 'A': {\n          value = String.fromCharCode(byteArray[p])\n          p += 1\n          break\n        }\n        case 'i': {\n          value = byteArray.readInt32LE(p)\n          p += 4\n          break\n        }\n        case 'I': {\n          value = byteArray.readUInt32LE(p)\n          p += 4\n          break\n        }\n        case 'c': {\n          value = byteArray.readInt8(p)\n          p += 1\n          break\n        }\n        case 'C': {\n          value = byteArray.readUInt8(p)\n          p += 1\n          break\n        }\n        case 's': {\n          value = byteArray.readInt16LE(p)\n          p += 2\n          break\n        }\n        case 'S': {\n          value = byteArray.readUInt16LE(p)\n          p += 2\n          break\n        }\n        case 'f': {\n          value = byteArray.readFloatLE(p)\n          p += 4\n          break\n        }\n        case 'Z':\n        case 'H': {\n          value = ''\n          while (p <= blockEnd) {\n            const cc = byteArray[p++]\n            if (cc === 0) {\n              break\n            } else {\n              value += String.fromCharCode(cc)\n            }\n          }\n          break\n        }\n        case 'B': {\n          value = ''\n          const cc = byteArray[p++]\n          const Btype = String.fromCharCode(cc)\n          const limit = byteArray.readInt32LE(p)\n          p += 4\n          if (Btype === 'i') {\n            if (tag === 'CG') {\n              for (let k = 0; k < limit; k++) {\n                const cigop = byteArray.readInt32LE(p)\n                const lop = cigop >> 4\n                const op = CIGAR_DECODER[cigop & 0xf]\n                value += lop + op\n                p += 4\n              }\n            } else {\n              for (let k = 0; k < limit; k++) {\n                value += byteArray.readInt32LE(p)\n                if (k + 1 < limit) {\n                  value += ','\n                }\n                p += 4\n              }\n            }\n          }\n          if (Btype === 'I') {\n            if (tag === 'CG') {\n              for (let k = 0; k < limit; k++) {\n                const cigop = byteArray.readUInt32LE(p)\n                const lop = cigop >> 4\n                const op = CIGAR_DECODER[cigop & 0xf]\n                value += lop + op\n                p += 4\n              }\n            } else {\n              for (let k = 0; k < limit; k++) {\n                value += byteArray.readUInt32LE(p)\n                if (k + 1 < limit) {\n                  value += ','\n                }\n                p += 4\n              }\n            }\n          }\n          if (Btype === 's') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readInt16LE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 2\n            }\n          }\n          if (Btype === 'S') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readUInt16LE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 2\n            }\n          }\n          if (Btype === 'c') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readInt8(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 1\n            }\n          }\n          if (Btype === 'C') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readUInt8(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 1\n            }\n          }\n          if (Btype === 'f') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readFloatLE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 4\n            }\n          }\n          break\n        }\n        default: {\n          console.warn(`Unknown BAM tag type '${type}', tags may be incomplete`)\n          value = undefined\n          p = blockEnd\n        } // stop parsing tags\n      }\n\n      this._tagOffset = p\n\n      this._tagList.push(tag)\n      if (lcTag === tagName) {\n        return value\n      }\n\n      this.data[lcTag] = value\n    }\n    this._allTagsParsed = true\n    return\n  }\n\n  _parseAllTags() {\n    this._parseTag('')\n  }\n\n  _parseCigar(cigar: string) {\n    return (\n      //@ts-ignore\n      cigar\n        .match(/\\d+\\D/g)\n        //@ts-ignore\n        .map(op => [op.match(/\\D/)[0].toUpperCase(), Number.parseInt(op, 10)])\n    )\n  }\n\n  /**\n   * @returns {boolean} true if the read is paired, regardless of whether both segments are mapped\n   */\n  isPaired() {\n    return !!(this.flags & Constants.BAM_FPAIRED)\n  }\n\n  /** @returns {boolean} true if the read is paired, and both segments are mapped */\n  isProperlyPaired() {\n    return !!(this.flags & Constants.BAM_FPROPER_PAIR)\n  }\n\n  /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n  isSegmentUnmapped() {\n    return !!(this.flags & Constants.BAM_FUNMAP)\n  }\n\n  /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n  isMateUnmapped() {\n    return !!(this.flags & Constants.BAM_FMUNMAP)\n  }\n\n  /** @returns {boolean} true if the read is mapped to the reverse strand */\n  isReverseComplemented() {\n    return !!(this.flags & Constants.BAM_FREVERSE)\n  }\n\n  /** @returns {boolean} true if the mate is mapped to the reverse strand */\n  isMateReverseComplemented() {\n    return !!(this.flags & Constants.BAM_FMREVERSE)\n  }\n\n  /** @returns {boolean} true if this is read number 1 in a pair */\n  isRead1() {\n    return !!(this.flags & Constants.BAM_FREAD1)\n  }\n\n  /** @returns {boolean} true if this is read number 2 in a pair */\n  isRead2() {\n    return !!(this.flags & Constants.BAM_FREAD2)\n  }\n\n  /** @returns {boolean} true if this is a secondary alignment */\n  isSecondary() {\n    return !!(this.flags & Constants.BAM_FSECONDARY)\n  }\n\n  /** @returns {boolean} true if this read has failed QC checks */\n  isFailedQc() {\n    return !!(this.flags & Constants.BAM_FQCFAIL)\n  }\n\n  /** @returns {boolean} true if the read is an optical or PCR duplicate */\n  isDuplicate() {\n    return !!(this.flags & Constants.BAM_FDUP)\n  }\n\n  /** @returns {boolean} true if this is a supplementary alignment */\n  isSupplementary() {\n    return !!(this.flags & Constants.BAM_FSUPPLEMENTARY)\n  }\n\n  cigar() {\n    if (this.isSegmentUnmapped()) {\n      return\n    }\n\n    const { byteArray, start } = this.bytes\n    const numCigarOps = this.get('_n_cigar_op')\n    let p = start + 36 + this.get('_l_read_name')\n    const seqLen = this.get('seq_length')\n    let cigar = ''\n    let lref = 0\n\n    // check for CG tag by inspecting whether the CIGAR field\n    // contains a clip that consumes entire seqLen\n    let cigop = byteArray.readInt32LE(p)\n    let lop = cigop >> 4\n    let op = CIGAR_DECODER[cigop & 0xf]\n    if (op === 'S' && lop === seqLen) {\n      // if there is a CG the second CIGAR field will\n      // be a N tag the represents the length on ref\n      p += 4\n      cigop = byteArray.readInt32LE(p)\n      lop = cigop >> 4\n      op = CIGAR_DECODER[cigop & 0xf]\n      if (op !== 'N') {\n        console.warn('CG tag with no N tag')\n      }\n      this.data.length_on_ref = lop\n      return this.get('CG')\n    } else {\n      for (let c = 0; c < numCigarOps; ++c) {\n        cigop = byteArray.readInt32LE(p)\n        lop = cigop >> 4\n        op = CIGAR_DECODER[cigop & 0xf]\n        cigar += lop + op\n\n        // soft clip, hard clip, and insertion don't count toward\n        // the length on the reference\n        if (op !== 'H' && op !== 'S' && op !== 'I') {\n          lref += lop\n        }\n\n        p += 4\n      }\n\n      this.data.length_on_ref = lref\n      return cigar\n    }\n  }\n\n  _flags() {}\n\n  length_on_ref() {\n    if (this.data.length_on_ref) {\n      return this.data.length_on_ref\n    } else {\n      this.get('cigar') // the length_on_ref is set as a side effect\n      return this.data.length_on_ref\n    }\n  }\n\n  _n_cigar_op() {\n    return this.get('_flag_nc') & 0xffff\n  }\n\n  _l_read_name() {\n    return this.get('_bin_mq_nl') & 0xff\n  }\n\n  /**\n   * number of bytes in the sequence field\n   */\n  _seq_bytes() {\n    return (this.get('seq_length') + 1) >> 1\n  }\n\n  getReadBases() {\n    return this.seq()\n  }\n\n  seq() {\n    const { byteArray, start } = this.bytes\n    const p =\n      start + 36 + this.get('_l_read_name') + this.get('_n_cigar_op') * 4\n    const seqBytes = this.get('_seq_bytes')\n    const len = this.get('seq_length')\n    let buf = ''\n    let i = 0\n    for (let j = 0; j < seqBytes; ++j) {\n      const sb = byteArray[p + j]\n      buf += SEQRET_DECODER[(sb & 0xf0) >> 4]\n      i++\n      if (i < len) {\n        buf += SEQRET_DECODER[sb & 0x0f]\n        i++\n      }\n    }\n    return buf\n  }\n\n  // adapted from igv.js\n  getPairOrientation() {\n    if (\n      !this.isSegmentUnmapped() &&\n      !this.isMateUnmapped() &&\n      this._refID === this._next_refid()\n    ) {\n      const s1 = this.isReverseComplemented() ? 'R' : 'F'\n      const s2 = this.isMateReverseComplemented() ? 'R' : 'F'\n      let o1 = ' '\n      let o2 = ' '\n      if (this.isRead1()) {\n        o1 = '1'\n        o2 = '2'\n      } else if (this.isRead2()) {\n        o1 = '2'\n        o2 = '1'\n      }\n\n      const tmp = []\n      const isize = this.template_length()\n      if (isize > 0) {\n        tmp[0] = s1\n        tmp[1] = o1\n        tmp[2] = s2\n        tmp[3] = o2\n      } else {\n        tmp[2] = s1\n        tmp[3] = o1\n        tmp[0] = s2\n        tmp[1] = o2\n      }\n      return tmp.join('')\n    }\n    return ''\n  }\n\n  _bin_mq_nl() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 12)\n  }\n\n  _flag_nc() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 16)\n  }\n\n  seq_length() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 20)\n  }\n\n  _next_refid() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 24)\n  }\n\n  _next_pos() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 28)\n  }\n\n  template_length() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 32)\n  }\n\n  toJSON() {\n    const data: { [key: string]: any } = {}\n    for (const k of Object.keys(this)) {\n      if (k.charAt(0) === '_' || k === 'bytes') {\n        continue\n      }\n      //@ts-ignore\n      data[k] = this[k]\n    }\n\n    return data\n  }\n}\n","export function parseHeaderText(text: string) {\n  const lines = text.split(/\\r?\\n/)\n  const data: { tag: string; data: { tag: string; value: string }[] }[] = []\n  for (const line of lines) {\n    const [tag, ...fields] = line.split(/\\t/)\n    if (tag) {\n      data.push({\n        tag: tag.slice(1),\n        data: fields.map(f => {\n          const [fieldTag, value] = f.split(':', 2)\n          return { tag: fieldTag, value }\n        }),\n      })\n    }\n  }\n  return data\n}\n","import { Buffer } from 'buffer'\nimport crc32 from 'buffer-crc32'\nimport { unzip, unzipChunkSlice } from '@gmod/bgzf-filehandle'\nimport { LocalFile, RemoteFile, GenericFilehandle } from 'generic-filehandle'\nimport AbortablePromiseCache from 'abortable-promise-cache'\nimport QuickLRU from 'quick-lru'\n\n// locals\nimport BAI from './bai'\nimport CSI from './csi'\nimport Chunk from './chunk'\nimport BAMFeature from './record'\nimport { parseHeaderText } from './sam'\nimport { checkAbortSignal, timeout, makeOpts, BamOpts, BaseOpts } from './util'\n\nexport const BAM_MAGIC = 21840194\n\nconst blockLen = 1 << 16\n\nasync function gen2array<T>(gen: AsyncIterable<T[]>): Promise<T[]> {\n  let out: T[] = []\n  for await (const x of gen) {\n    out = out.concat(x)\n  }\n  return out\n}\n\ninterface Args {\n  chunk: Chunk\n  opts: BaseOpts\n}\n\nclass NullFilehandle {\n  public read(): Promise<any> {\n    throw new Error('never called')\n  }\n  public stat(): Promise<any> {\n    throw new Error('never called')\n  }\n\n  public readFile(): Promise<any> {\n    throw new Error('never called')\n  }\n\n  public close(): Promise<any> {\n    throw new Error('never called')\n  }\n}\nexport default class BamFile {\n  public renameRefSeq: (a: string) => string\n  public bam: GenericFilehandle\n  public header?: string\n  public chrToIndex?: Record<string, number>\n  public indexToChr?: { refName: string; length: number }[]\n  public yieldThreadTime: number\n  public index?: BAI | CSI\n  public htsget = false\n  public headerP?: ReturnType<BamFile['getHeaderPre']>\n\n  private featureCache = new AbortablePromiseCache<Args, BAMFeature[]>({\n    cache: new QuickLRU({\n      maxSize: 50,\n    }),\n    fill: async (args: Args, signal) => {\n      const { chunk, opts } = args\n      const { data, cpositions, dpositions } = await this._readChunk({\n        chunk,\n        opts: { ...opts, signal },\n      })\n      return this.readBamFeatures(data, cpositions, dpositions, chunk)\n    },\n  })\n\n  constructor({\n    bamFilehandle,\n    bamPath,\n    bamUrl,\n    baiPath,\n    baiFilehandle,\n    baiUrl,\n    csiPath,\n    csiFilehandle,\n    csiUrl,\n    htsget,\n    yieldThreadTime = 100,\n    renameRefSeqs = n => n,\n  }: {\n    bamFilehandle?: GenericFilehandle\n    bamPath?: string\n    bamUrl?: string\n    baiPath?: string\n    baiFilehandle?: GenericFilehandle\n    baiUrl?: string\n    csiPath?: string\n    csiFilehandle?: GenericFilehandle\n    csiUrl?: string\n    renameRefSeqs?: (a: string) => string\n    yieldThreadTime?: number\n    htsget?: boolean\n  }) {\n    this.renameRefSeq = renameRefSeqs\n\n    if (bamFilehandle) {\n      this.bam = bamFilehandle\n    } else if (bamPath) {\n      this.bam = new LocalFile(bamPath)\n    } else if (bamUrl) {\n      this.bam = new RemoteFile(bamUrl)\n    } else if (htsget) {\n      this.htsget = true\n      this.bam = new NullFilehandle()\n    } else {\n      throw new Error('unable to initialize bam')\n    }\n    if (csiFilehandle) {\n      this.index = new CSI({ filehandle: csiFilehandle })\n    } else if (csiPath) {\n      this.index = new CSI({ filehandle: new LocalFile(csiPath) })\n    } else if (csiUrl) {\n      this.index = new CSI({ filehandle: new RemoteFile(csiUrl) })\n    } else if (baiFilehandle) {\n      this.index = new BAI({ filehandle: baiFilehandle })\n    } else if (baiPath) {\n      this.index = new BAI({ filehandle: new LocalFile(baiPath) })\n    } else if (baiUrl) {\n      this.index = new BAI({ filehandle: new RemoteFile(baiUrl) })\n    } else if (bamPath) {\n      this.index = new BAI({ filehandle: new LocalFile(`${bamPath}.bai`) })\n    } else if (bamUrl) {\n      this.index = new BAI({ filehandle: new RemoteFile(`${bamUrl}.bai`) })\n    } else if (htsget) {\n      this.htsget = true\n    } else {\n      throw new Error('unable to infer index format')\n    }\n    this.yieldThreadTime = yieldThreadTime\n  }\n\n  async getHeaderPre(origOpts?: BaseOpts) {\n    const opts = makeOpts(origOpts)\n    if (!this.index) {\n      return\n    }\n    const indexData = await this.index.parse(opts)\n    const ret = indexData.firstDataLine\n      ? indexData.firstDataLine.blockPosition + 65535\n      : undefined\n    let buffer\n    if (ret) {\n      const s = ret + blockLen\n      const res = await this.bam.read(Buffer.alloc(s), 0, s, 0, opts)\n      if (!res.bytesRead) {\n        throw new Error('Error reading header')\n      }\n      buffer = res.buffer.subarray(0, Math.min(res.bytesRead, ret))\n    } else {\n      buffer = (await this.bam.readFile(opts)) as Buffer\n    }\n\n    const uncba = await unzip(buffer)\n\n    if (uncba.readInt32LE(0) !== BAM_MAGIC) {\n      throw new Error('Not a BAM file')\n    }\n    const headLen = uncba.readInt32LE(4)\n\n    this.header = uncba.toString('utf8', 8, 8 + headLen)\n    const { chrToIndex, indexToChr } = await this._readRefSeqs(\n      headLen + 8,\n      65535,\n      opts,\n    )\n    this.chrToIndex = chrToIndex\n    this.indexToChr = indexToChr\n\n    return parseHeaderText(this.header)\n  }\n\n  getHeader(opts?: BaseOpts) {\n    if (!this.headerP) {\n      this.headerP = this.getHeaderPre(opts).catch(e => {\n        this.headerP = undefined\n        throw e\n      })\n    }\n    return this.headerP\n  }\n\n  async getHeaderText(opts: BaseOpts = {}) {\n    await this.getHeader(opts)\n    return this.header\n  }\n\n  // the full length of the refseq block is not given in advance so this grabs\n  // a chunk and doubles it if all refseqs haven't been processed\n  async _readRefSeqs(\n    start: number,\n    refSeqBytes: number,\n    opts?: BaseOpts,\n  ): Promise<{\n    chrToIndex: { [key: string]: number }\n    indexToChr: { refName: string; length: number }[]\n  }> {\n    if (start > refSeqBytes) {\n      return this._readRefSeqs(start, refSeqBytes * 2, opts)\n    }\n    const size = refSeqBytes + blockLen\n    const { bytesRead, buffer } = await this.bam.read(\n      Buffer.alloc(size),\n      0,\n      refSeqBytes,\n      0,\n      opts,\n    )\n    if (!bytesRead) {\n      throw new Error('Error reading refseqs from header')\n    }\n    const uncba = await unzip(\n      buffer.subarray(0, Math.min(bytesRead, refSeqBytes)),\n    )\n    const nRef = uncba.readInt32LE(start)\n    let p = start + 4\n    const chrToIndex: { [key: string]: number } = {}\n    const indexToChr: { refName: string; length: number }[] = []\n    for (let i = 0; i < nRef; i += 1) {\n      const lName = uncba.readInt32LE(p)\n      const refName = this.renameRefSeq(\n        uncba.toString('utf8', p + 4, p + 4 + lName - 1),\n      )\n      const lRef = uncba.readInt32LE(p + lName + 4)\n\n      chrToIndex[refName] = i\n      indexToChr.push({ refName, length: lRef })\n\n      p = p + 8 + lName\n      if (p > uncba.length) {\n        console.warn(\n          `BAM header is very big.  Re-fetching ${refSeqBytes} bytes.`,\n        )\n        return this._readRefSeqs(start, refSeqBytes * 2, opts)\n      }\n    }\n    return { chrToIndex, indexToChr }\n  }\n\n  async getRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    return gen2array(this.streamRecordsForRange(chr, min, max, opts))\n  }\n\n  async *streamRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    await this.getHeader(opts)\n    const chrId = this.chrToIndex?.[chr]\n    if (chrId === undefined || !this.index) {\n      yield []\n    } else {\n      const chunks = await this.index.blocksForRange(chrId, min - 1, max, opts)\n      yield* this._fetchChunkFeatures(chunks, chrId, min, max, opts)\n    }\n  }\n\n  async *_fetchChunkFeatures(\n    chunks: Chunk[],\n    chrId: number,\n    min: number,\n    max: number,\n    opts: BamOpts = {},\n  ) {\n    const { viewAsPairs } = opts\n    const feats = [] as BAMFeature[][]\n    let done = false\n\n    for (const chunk of chunks) {\n      const records = await this.featureCache.get(\n        chunk.toString(),\n        { chunk, opts },\n        opts.signal,\n      )\n\n      const recs = [] as BAMFeature[]\n      for (const feature of records) {\n        if (feature.seq_id() === chrId) {\n          if (feature.get('start') >= max) {\n            // past end of range, can stop iterating\n            done = true\n            break\n          } else if (feature.get('end') >= min) {\n            // must be in range\n            recs.push(feature)\n          }\n        }\n      }\n      feats.push(recs)\n      yield recs\n      if (done) {\n        break\n      }\n    }\n\n    checkAbortSignal(opts.signal)\n    if (viewAsPairs) {\n      yield this.fetchPairs(chrId, feats, opts)\n    }\n  }\n\n  async fetchPairs(chrId: number, feats: BAMFeature[][], opts: BamOpts) {\n    const { pairAcrossChr, maxInsertSize = 200000 } = opts\n    const unmatedPairs: { [key: string]: boolean } = {}\n    const readIds: { [key: string]: number } = {}\n    feats.map(ret => {\n      const readNames: { [key: string]: number } = {}\n      for (const element of ret) {\n        const name = element.name()\n        const id = element.id()\n        if (!readNames[name]) {\n          readNames[name] = 0\n        }\n        readNames[name]++\n        readIds[id] = 1\n      }\n      for (const [k, v] of Object.entries(readNames)) {\n        if (v === 1) {\n          unmatedPairs[k] = true\n        }\n      }\n    })\n\n    const matePromises: Promise<Chunk[]>[] = []\n    feats.map(ret => {\n      for (const f of ret) {\n        const name = f.name()\n        const start = f.get('start')\n        const pnext = f._next_pos()\n        const rnext = f._next_refid()\n        if (\n          this.index &&\n          unmatedPairs[name] &&\n          (pairAcrossChr ||\n            (rnext === chrId && Math.abs(start - pnext) < maxInsertSize))\n        ) {\n          matePromises.push(\n            this.index.blocksForRange(rnext, pnext, pnext + 1, opts),\n          )\n        }\n      }\n    })\n\n    // filter out duplicate chunks (the blocks are lists of chunks, blocks are\n    // concatenated, then filter dup chunks)\n    const map = new Map<string, Chunk>()\n    const res = await Promise.all(matePromises)\n    for (const m of res.flat()) {\n      if (!map.has(m.toString())) {\n        map.set(m.toString(), m)\n      }\n    }\n\n    const mateFeatPromises = await Promise.all(\n      [...map.values()].map(async c => {\n        const { data, cpositions, dpositions, chunk } = await this._readChunk({\n          chunk: c,\n          opts,\n        })\n        const mateRecs = [] as BAMFeature[]\n        for (const feature of await this.readBamFeatures(\n          data,\n          cpositions,\n          dpositions,\n          chunk,\n        )) {\n          if (unmatedPairs[feature.get('name')] && !readIds[feature.id()]) {\n            mateRecs.push(feature)\n          }\n        }\n        return mateRecs\n      }),\n    )\n    return mateFeatPromises.flat()\n  }\n\n  async _readRegion(position: number, size: number, opts: BaseOpts = {}) {\n    const { bytesRead, buffer } = await this.bam.read(\n      Buffer.alloc(size),\n      0,\n      size,\n      position,\n      opts,\n    )\n\n    return buffer.subarray(0, Math.min(bytesRead, size))\n  }\n\n  async _readChunk({ chunk, opts }: { chunk: Chunk; opts: BaseOpts }) {\n    const buffer = await this._readRegion(\n      chunk.minv.blockPosition,\n      chunk.fetchedSize(),\n      opts,\n    )\n\n    const {\n      buffer: data,\n      cpositions,\n      dpositions,\n    } = await unzipChunkSlice(buffer, chunk)\n    return { data, cpositions, dpositions, chunk }\n  }\n\n  async readBamFeatures(\n    ba: Buffer,\n    cpositions: number[],\n    dpositions: number[],\n    chunk: Chunk,\n  ) {\n    let blockStart = 0\n    const sink = [] as BAMFeature[]\n    let pos = 0\n    let last = +Date.now()\n\n    while (blockStart + 4 < ba.length) {\n      const blockSize = ba.readInt32LE(blockStart)\n      const blockEnd = blockStart + 4 + blockSize - 1\n\n      // increment position to the current decompressed status\n      if (dpositions) {\n        while (blockStart + chunk.minv.dataPosition >= dpositions[pos++]) {}\n        pos--\n      }\n\n      // only try to read the feature if we have all the bytes for it\n      if (blockEnd < ba.length) {\n        const feature = new BAMFeature({\n          bytes: {\n            byteArray: ba,\n            start: blockStart,\n            end: blockEnd,\n          },\n          // the below results in an automatically calculated file-offset based\n          // ID if the info for that is available, otherwise crc32 of the\n          // features\n          //\n          // cpositions[pos] refers to actual file offset of a bgzip block\n          // boundaries\n          //\n          // we multiply by (1 <<8) in order to make sure each block has a\n          // \"unique\" address space so that data in that block could never\n          // overlap\n          //\n          // then the blockStart-dpositions is an uncompressed file offset from\n          // that bgzip block boundary, and since the cpositions are multiplied\n          // by (1 << 8) these uncompressed offsets get a unique space\n          //\n          // this has an extra chunk.minv.dataPosition added on because it\n          // blockStart starts at 0 instead of chunk.minv.dataPosition\n          //\n          // the +1 is just to avoid any possible uniqueId 0 but this does not\n          // realistically happen\n          fileOffset:\n            cpositions.length > 0\n              ? cpositions[pos] * (1 << 8) +\n                (blockStart - dpositions[pos]) +\n                chunk.minv.dataPosition +\n                1\n              : // must be slice, not subarray for buffer polyfill on web\n                crc32.signed(ba.slice(blockStart, blockEnd)),\n        })\n\n        sink.push(feature)\n        if (this.yieldThreadTime && +Date.now() - last > this.yieldThreadTime) {\n          await timeout(1)\n          last = +Date.now()\n        }\n      }\n\n      blockStart = blockEnd + 1\n    }\n    return sink\n  }\n\n  async hasRefSeq(seqName: string) {\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined ? false : this.index?.hasRefSeq(seqId)\n  }\n\n  async lineCount(seqName: string) {\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined || !this.index ? 0 : this.index.lineCount(seqId)\n  }\n\n  async indexCov(seqName: string, start?: number, end?: number) {\n    if (!this.index) {\n      return []\n    }\n    await this.index.parse()\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined ? [] : this.index.indexCov(seqId, start, end)\n  }\n\n  async blocksForRange(\n    seqName: string,\n    start: number,\n    end: number,\n    opts?: BaseOpts,\n  ) {\n    if (!this.index) {\n      return []\n    }\n    await this.index.parse()\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined\n      ? []\n      : this.index.blocksForRange(seqId, start, end, opts)\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\nimport { Buffer } from 'buffer'\nimport { BaseOpts, BamOpts } from './util'\nimport BamFile, { BAM_MAGIC } from './bamFile'\nimport Chunk from './chunk'\nimport { parseHeaderText } from './sam'\n\ninterface HtsgetChunk {\n  url: string\n  headers?: Record<string, string>\n}\nasync function concat(arr: HtsgetChunk[], opts?: Record<string, any>) {\n  const res = await Promise.all(\n    arr.map(async chunk => {\n      const { url, headers } = chunk\n      if (url.startsWith('data:')) {\n        return Buffer.from(url.split(',')[1], 'base64')\n      } else {\n        //remove referer header, it is not even allowed to be specified\n        // @ts-expect-error\n        //eslint-disable-next-line @typescript-eslint/no-unused-vars\n        const { referer, ...rest } = headers\n        const res = await fetch(url, {\n          ...opts,\n          headers: { ...opts?.headers, ...rest },\n        })\n        if (!res.ok) {\n          throw new Error(\n            `HTTP ${res.status} fetching ${url}: ${await res.text()}`,\n          )\n        }\n        return Buffer.from(await res.arrayBuffer())\n      }\n    }),\n  )\n\n  return Buffer.concat(await Promise.all(res.map(elt => unzip(elt))))\n}\n\nexport default class HtsgetFile extends BamFile {\n  private baseUrl: string\n\n  private trackId: string\n\n  constructor(args: { trackId: string; baseUrl: string }) {\n    super({ htsget: true })\n    this.baseUrl = args.baseUrl\n    this.trackId = args.trackId\n  }\n\n  async *streamRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    const base = `${this.baseUrl}/${this.trackId}`\n    const url = `${base}?referenceName=${chr}&start=${min}&end=${max}&format=BAM`\n    const chrId = this.chrToIndex?.[chr]\n    if (chrId === undefined) {\n      yield []\n    } else {\n      const result = await fetch(url, { ...opts })\n      if (!result.ok) {\n        throw new Error(\n          `HTTP ${result.status} fetching ${url}: ${await result.text()}`,\n        )\n      }\n      const data = await result.json()\n      const uncba = await concat(data.htsget.urls.slice(1), opts)\n\n      yield* this._fetchChunkFeatures(\n        [\n          // fake stuff to pretend to be a Chunk\n          {\n            buffer: uncba,\n            _fetchedSize: undefined,\n            bin: 0,\n            compareTo() {\n              return 0\n            },\n            toUniqueString() {\n              return `${chr}_${min}_${max}`\n            },\n            fetchedSize() {\n              return 0\n            },\n            minv: {\n              dataPosition: 0,\n              blockPosition: 0,\n              compareTo: () => 0,\n            },\n            maxv: {\n              dataPosition: Number.MAX_SAFE_INTEGER,\n              blockPosition: 0,\n              compareTo: () => 0,\n            },\n            toString() {\n              return `${chr}_${min}_${max}`\n            },\n          },\n        ],\n        chrId,\n        min,\n        max,\n        opts,\n      )\n    }\n  }\n\n  async _readChunk({ chunk }: { chunk: Chunk; opts: BaseOpts }) {\n    if (!chunk.buffer) {\n      throw new Error('expected chunk.buffer in htsget')\n    }\n    return { data: chunk.buffer, cpositions: [], dpositions: [], chunk }\n  }\n\n  async getHeader(opts: BaseOpts = {}) {\n    const url = `${this.baseUrl}/${this.trackId}?referenceName=na&class=header`\n    const result = await fetch(url, opts)\n    if (!result.ok) {\n      throw new Error(\n        `HTTP ${result.status} fetching ${url}: ${await result.text()}`,\n      )\n    }\n    const data = await result.json()\n    const uncba = await concat(data.htsget.urls, opts)\n\n    if (uncba.readInt32LE(0) !== BAM_MAGIC) {\n      throw new Error('Not a BAM file')\n    }\n    const headLen = uncba.readInt32LE(4)\n    const headerText = uncba.toString('utf8', 8, 8 + headLen)\n    const samHeader = parseHeaderText(headerText)\n\n    // use the @SQ lines in the header to figure out the\n    // mapping between ref ref ID numbers and names\n    const idToName: { refName: string; length: number }[] = []\n    const nameToId: Record<string, number> = {}\n    const sqLines = samHeader.filter(l => l.tag === 'SQ')\n    for (const [refId, sqLine] of sqLines.entries()) {\n      let refName = ''\n      let length = 0\n      for (const item of sqLine.data) {\n        if (item.tag === 'SN') {\n          refName = item.value\n        } else if (item.tag === 'LN') {\n          length = +item.value\n        }\n      }\n      nameToId[refName] = refId\n      idToName[refId] = { refName, length }\n    }\n    this.chrToIndex = nameToId\n    this.indexToChr = idToName\n    return samHeader\n  }\n}\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortcontroller_ponyfill_1 = require(\"./abortcontroller-ponyfill\");\nconst AggregateAbortController_1 = __importDefault(require(\"./AggregateAbortController\"));\nconst AggregateStatusReporter_1 = __importDefault(require(\"./AggregateStatusReporter\"));\nclass AbortablePromiseCache {\n    constructor({ fill, cache, }) {\n        if (typeof fill !== 'function') {\n            throw new TypeError('must pass a fill function');\n        }\n        if (typeof cache !== 'object') {\n            throw new TypeError('must pass a cache object');\n        }\n        if (typeof cache.get !== 'function' ||\n            typeof cache.set !== 'function' ||\n            typeof cache.delete !== 'function') {\n            throw new TypeError('cache must implement get(key), set(key, val), and and delete(key)');\n        }\n        this.cache = cache;\n        this.fillCallback = fill;\n    }\n    static isAbortException(exception) {\n        return (\n        // DOMException\n        exception.name === 'AbortError' ||\n            // standard-ish non-DOM abort exception\n            //@ts-ignore\n            exception.code === 'ERR_ABORTED' ||\n            // stringified DOMException\n            exception.message === 'AbortError: aborted' ||\n            // stringified standard-ish exception\n            exception.message === 'Error: aborted');\n    }\n    evict(key, entry) {\n        if (this.cache.get(key) === entry) {\n            this.cache.delete(key);\n        }\n    }\n    fill(key, data, signal, statusCallback) {\n        const aborter = new AggregateAbortController_1.default();\n        const statusReporter = new AggregateStatusReporter_1.default();\n        statusReporter.addCallback(statusCallback);\n        const newEntry = {\n            aborter: aborter,\n            promise: this.fillCallback(data, aborter.signal, (message) => {\n                statusReporter.callback(message);\n            }),\n            settled: false,\n            statusReporter,\n            get aborted() {\n                return this.aborter.signal.aborted;\n            },\n        };\n        newEntry.aborter.addSignal(signal);\n        // remove the fill from the cache when its abortcontroller fires, if still in there\n        newEntry.aborter.signal.addEventListener('abort', () => {\n            if (!newEntry.settled) {\n                this.evict(key, newEntry);\n            }\n        });\n        // chain off the cached promise to record when it settles\n        newEntry.promise\n            .then(() => {\n            newEntry.settled = true;\n        }, () => {\n            newEntry.settled = true;\n            // if the fill throws an error (including abort) and is still in the cache, remove it\n            this.evict(key, newEntry);\n        })\n            .catch(e => {\n            // this will only be reached if there is some kind of\n            // bad bug in this library\n            console.error(e);\n            throw e;\n        });\n        this.cache.set(key, newEntry);\n    }\n    static checkSinglePromise(promise, signal) {\n        // check just this signal for having been aborted, and abort the\n        // promise if it was, regardless of what happened with the cached\n        // response\n        function checkForSingleAbort() {\n            if (signal && signal.aborted) {\n                throw Object.assign(new Error('aborted'), { code: 'ERR_ABORTED' });\n            }\n        }\n        return promise.then(result => {\n            checkForSingleAbort();\n            return result;\n        }, error => {\n            checkForSingleAbort();\n            throw error;\n        });\n    }\n    has(key) {\n        return this.cache.has(key);\n    }\n    /**\n     * Callback for getting status of the pending async\n     *\n     * @callback statusCallback\n     * @param {any} status, current status string or message object\n     */\n    /**\n     * @param {any} key cache key to use for this request\n     * @param {any} data data passed as the first argument to the fill callback\n     * @param {AbortSignal} [signal] optional AbortSignal object that aborts the request\n     * @param {statusCallback} a callback to get the current status of a pending async operation\n     */\n    get(key, data, signal, statusCallback) {\n        if (!signal && data instanceof abortcontroller_ponyfill_1.AbortSignal) {\n            throw new TypeError('second get argument appears to be an AbortSignal, perhaps you meant to pass `null` for the fill data?');\n        }\n        const cacheEntry = this.cache.get(key);\n        if (cacheEntry) {\n            if (cacheEntry.aborted && !cacheEntry.settled) {\n                // if it's aborted but has not realized it yet, evict it and redispatch\n                this.evict(key, cacheEntry);\n                return this.get(key, data, signal, statusCallback);\n            }\n            if (cacheEntry.settled) {\n                // too late to abort, just return it\n                return cacheEntry.promise;\n            }\n            // request is in-flight, add this signal to its list of signals,\n            // or if there is no signal, the aborter will become non-abortable\n            cacheEntry.aborter.addSignal(signal);\n            cacheEntry.statusReporter.addCallback(statusCallback);\n            return AbortablePromiseCache.checkSinglePromise(cacheEntry.promise, signal);\n        }\n        // if we got here, it is not in the cache. fill.\n        this.fill(key, data, signal, statusCallback);\n        return AbortablePromiseCache.checkSinglePromise(\n        //see https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#non-null-assertion-operator-postfix-\n        //eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        this.cache.get(key).promise, signal);\n    }\n    /**\n     * delete the given entry from the cache. if it exists and its fill request has\n     * not yet settled, the fill will be signaled to abort.\n     *\n     * @param {any} key\n     */\n    delete(key) {\n        const cachedEntry = this.cache.get(key);\n        if (cachedEntry) {\n            if (!cachedEntry.settled) {\n                cachedEntry.aborter.abort();\n            }\n            this.cache.delete(key);\n        }\n    }\n    /**\n     * Clear all requests from the cache. Aborts any that have not settled.\n     * @returns {number} count of entries deleted\n     */\n    clear() {\n        // iterate without needing regenerator-runtime\n        const keyIter = this.cache.keys();\n        let deleteCount = 0;\n        for (let result = keyIter.next(); !result.done; result = keyIter.next()) {\n            this.delete(result.value);\n            deleteCount += 1;\n        }\n        return deleteCount;\n    }\n}\nexports.default = AbortablePromiseCache;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortcontroller_ponyfill_1 = require(\"./abortcontroller-ponyfill\");\nclass NullSignal {\n}\n/**\n * aggregates a number of abort signals, will only fire the aggregated\n * abort if all of the input signals have been aborted\n */\nclass AggregateAbortController {\n    constructor() {\n        this.signals = new Set();\n        this.abortController = new abortcontroller_ponyfill_1.AbortController();\n    }\n    /**\n     * @param {AbortSignal} [signal] optional AbortSignal to add. if falsy,\n     *  will be treated as a null-signal, and this abortcontroller will no\n     *  longer be abortable.\n     */\n    //@ts-ignore\n    addSignal(signal = new NullSignal()) {\n        if (this.signal.aborted) {\n            throw new Error('cannot add a signal, already aborted!');\n        }\n        // note that a NullSignal will never fire, so if we\n        // have one this thing will never actually abort\n        this.signals.add(signal);\n        if (signal.aborted) {\n            // handle the abort immediately if it is already aborted\n            // for some reason\n            this.handleAborted(signal);\n        }\n        else if (typeof signal.addEventListener === 'function') {\n            signal.addEventListener('abort', () => {\n                this.handleAborted(signal);\n            });\n        }\n    }\n    handleAborted(signal) {\n        this.signals.delete(signal);\n        if (this.signals.size === 0) {\n            this.abortController.abort();\n        }\n    }\n    get signal() {\n        return this.abortController.signal;\n    }\n    abort() {\n        this.abortController.abort();\n    }\n}\nexports.default = AggregateAbortController;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass AggregateStatusReporter {\n    constructor() {\n        this.callbacks = new Set();\n    }\n    addCallback(callback = () => { }) {\n        this.callbacks.add(callback);\n        callback(this.currentMessage);\n    }\n    callback(message) {\n        this.currentMessage = message;\n        this.callbacks.forEach(elt => {\n            elt(message);\n        });\n    }\n}\nexports.default = AggregateStatusReporter;\n","\"use strict\";\n/* eslint-disable */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AbortSignal = exports.AbortController = void 0;\nconst cjs_ponyfill_1 = require(\"abortcontroller-polyfill/dist/cjs-ponyfill\");\nvar getGlobal = function () {\n    // the only reliable means to get the global object is\n    // `Function('return this')()`\n    // However, this causes CSP violations in Chrome apps.\n    if (typeof self !== 'undefined') {\n        return self;\n    }\n    if (typeof window !== 'undefined') {\n        return window;\n    }\n    if (typeof global !== 'undefined') {\n        return global;\n    }\n    throw new Error('unable to locate global object');\n};\n//@ts-ignore\nlet AbortController = typeof getGlobal().AbortController === 'undefined' ? cjs_ponyfill_1.AbortController : getGlobal().AbortController;\nexports.AbortController = AbortController;\n//@ts-ignore\nlet AbortSignal = typeof getGlobal().AbortController === 'undefined' ? cjs_ponyfill_1.AbortSignal : getGlobal().AbortSignal;\nexports.AbortSignal = AbortSignal;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst AbortablePromiseCache_1 = __importDefault(require(\"./AbortablePromiseCache\"));\nexports.default = AbortablePromiseCache_1.default;\n"],"names":["VirtualOffset","constructor","blockPosition","dataPosition","this","toString","concat","compareTo","b","min","i","_len","arguments","length","args","Array","_key","fromBytes","bytes","offset","undefined","Error","Chunk","minv","maxv","bin","_fetchedSize","toUniqueString","fetchedSize","timeout","ms","Promise","resolve","setTimeout","checkAbortSignal","signal","aborted","DOMException","e","code","optimizeChunks","chunks","lowest","mergedChunks","lastChunk","sort","c0","c1","dif","chunk","push","chunk1","chunk2","parsePseudoBin","lineCount","long","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","longToNumber","Long","prototype","slice","call","findFirstData","firstDataLine","virtualOffset","parseNameBytes","namesBytes","renameRefSeq","s","currRefId","currNameStart","refIdToName","refNameToId","refName","IndexFile","_ref","filehandle","n","BAI","refId","opts","_b","_a","parse","indices","stats","_parse","readFile","readUInt32LE","refCount","readInt32LE","curr","binCount","binIndex","j","binLimit","chunkCount","k","u","v","linearCount","linearIndex","bai","maxBlockSize","indexCov","seqId","start","end","range","seqIdx","multiple","roundDown","depths","totalSize","currentPos","score","map","d","blocksForRange","max","indexData","ba","overlappingBins","beg","binChunks","binChunk","nintv","minLin","Math","maxLin","vp","setupP","catch","hasRefSeq","rshift","num","bits","floor","CSI","maxBinNumber","depth","minShift","parseAuxData","formatFlags","coordinateType","format","columnNumbers","ref","metaValue","metaChar","String","fromCharCode","skipLines","nameSectionLength","subarray","buffer","unzip","csiVersion","auxLength","aux","csi","reg2bins","c","l","t","bins","SEQRET_DECODER","split","CIGAR_DECODER","BamRecord","data","_tagList","_allTagsParsed","fileOffset","byteArray","_id","_refID","flags","get","field","_get","toLowerCase","seq_id","_parseTag","_tags","_parseAllTags","tags","isSegmentUnmapped","isPaired","Object","keys","seen","filter","lt","parent","children","id","mq","qual","qualRaw","join","p","lseq","strand","isReverseComplemented","multi_segment_next_segment_strand","isMateUnmapped","isMateReverseComplemented","name","_read_name","nl","tagName","_tagOffset","blockEnd","lcTag","tag","type","value","readInt8","readUInt8","readInt16LE","readUInt16LE","readFloatLE","cc","Btype","limit","cigop","console","warn","_parseCigar","cigar","match","op","toUpperCase","parseInt","Constants","isProperlyPaired","isRead1","isRead2","isSecondary","isFailedQc","isDuplicate","isSupplementary","numCigarOps","seqLen","lref","lop","length_on_ref","_flags","_n_cigar_op","_l_read_name","_seq_bytes","getReadBases","seq","seqBytes","len","buf","sb","getPairOrientation","_next_refid","s1","s2","o1","o2","tmp","template_length","_bin_mq_nl","_flag_nc","seq_length","_next_pos","toJSON","charAt","parseHeaderText","text","lines","line","fields","f","fieldTag","BAM_MAGIC","NullFilehandle","read","stat","close","BamFile","bamFilehandle","bamPath","bamUrl","baiPath","baiFilehandle","baiUrl","csiPath","csiFilehandle","csiUrl","htsget","yieldThreadTime","renameRefSeqs","featureCache","AbortablePromiseCache","cache","QuickLRU","maxSize","fill","async","cpositions","dpositions","_readChunk","readBamFeatures","bam","LocalFile","RemoteFile","index","getHeaderPre","origOpts","obj","makeOpts","ret","res","Buffer","alloc","bytesRead","uncba","headLen","header","chrToIndex","indexToChr","_readRefSeqs","getHeader","headerP","getHeaderText","refSeqBytes","size","nRef","lName","lRef","getRecordsForRange","chr","gen","out","x","gen2array","streamRecordsForRange","chrId","_fetchChunkFeatures","_this","viewAsPairs","feats","done","records","recs","feature","fetchPairs","reject","pairAcrossChr","maxInsertSize","unmatedPairs","readIds","readNames","element","entries","matePromises","pnext","rnext","abs","Map","all","m","flat","has","set","values","mateRecs","_readRegion","position","_ref2","unzipChunkSlice","blockStart","sink","pos","last","Date","now","BAMFeature","crc32","seqName","arr","url","headers","startsWith","from","referer","rest","fetch","ok","status","arrayBuffer","elt","HtsgetFile","super","baseUrl","trackId","base","result","json","urls","samHeader","idToName","nameToId","sqLines","sqLine","item","__importDefault","mod","__esModule","defineProperty","exports","abortcontroller_ponyfill_1","require","AggregateAbortController_1","AggregateStatusReporter_1","TypeError","delete","fillCallback","isAbortException","exception","message","evict","key","entry","statusCallback","aborter","default","statusReporter","addCallback","newEntry","promise","callback","settled","addSignal","addEventListener","then","error","checkSinglePromise","checkForSingleAbort","assign","AbortSignal","cacheEntry","cachedEntry","abort","clear","keyIter","deleteCount","next","NullSignal","signals","Set","abortController","AbortController","add","handleAborted","callbacks","currentMessage","forEach","cjs_ponyfill_1","getGlobal","self","window","global","AbortablePromiseCache_1"],"sourceRoot":""}